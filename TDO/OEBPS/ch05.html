<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:pls="http://www.w3.org/2005/01/pronunciation-lexicon" xmlns:ssml="http://www.w3.org/2001/10/synthesis" xmlns:svg="http://www.w3.org/2000/svg"><head><title>Chapter 5. Describing Relationships and Structures</title><link rel="stylesheet" type="text/css" href="core.css"/><meta name="generator" content="DocBook XSL Stylesheets V1.76.1"/><meta name="keywords" content="relationships, semantic perspective, lexical perspective, structural perspective, implementation ive, architectural perspective, triple, vocabulary problem, inclusion, possession, taxonomy, ontology, controlled vocabulary, thesaurus, hypertext, links"/><meta name="keywords" content="organizing, information, resources, metadata, resource description"/><link rel="up" href="index.html" title="The Discipline of Organizing"/><link rel="prev" href="ch04.html" title="Chapter 4. Resource Description and Metadata"/><link rel="next" href="ch06.html" title="Chapter 6. Categorization: Describing Resource Classes and Types"/></head><body><section class="chapter" title="Chapter 5. Describing Relationships and Structures" epub:type="chapter" id="chapter-5"><div class="titlepage"><div><div><h2 class="title">Chapter 5. Describing Relationships and Structures</h2></div><div><div class="author"><h3 class="author"><span class="firstname">Robert</span> <span class="othername">J.</span> <span class="surname">Glushko</span></h3></div></div><div><div class="author"><h3 class="author"><span class="firstname">Matthew</span> <span class="surname">Mayernik</span></h3></div></div><div><div class="author"><h3 class="author"><span class="firstname">Alberto</span> <span class="surname">Pepe</span></h3></div></div><div><div class="author"><h3 class="author"><span class="firstname">Murray</span> <span class="surname">Maloney</span></h3></div></div></div></div><div class="sect1" title="Introduction"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="section-5.1">Introduction</h2></div></div></div><p>We can consider a family to be a collection of people affiliated by some connections
            with each other such as common ancestors or a common residence. The Simpson family
            includes a man named Homer and a woman named Marge, the married parents of three sibling
            children, a boy named Bart and two girls, Lisa and Maggie. This is a magical
            family that speaks many languages, but always uses the language of the local television station. In the
            English-speaking Simpson family, the boy describes his parents as his father and mother
            and his two siblings as his sisters. In the Spanish speaking Simpson family the boy
            refers to his parents as <span xml:lang="es" class="foreignphrase"><em xml:lang="es" class="foreignphrase">su padre y su madre</em></span>
            and his sisters are <span xml:lang="es" class="foreignphrase"><em xml:lang="es" class="foreignphrase">las hermanas</em></span>. In the
            Chinese Simpson family Lisa and Maggie refer to each other according to their
            relative ages; Lisa, the elder sister as <span xml:lang="cn" class="foreignphrase"><em xml:lang="cn" class="foreignphrase">jiě
                jie</em></span> and, Maggie, the younger sister as <span xml:lang="cn" class="foreignphrase"><em xml:lang="cn" class="foreignphrase">mèi mei</em></span>.<sup>[<a id="chapter-5-endnote-01" href="#ftn.chapter-5-endnote-01" class="footnote">253</a>]</sup></p><p><a id="id622250" class="indexterm"/>Kinship relationships are ubiquitous and widely studied, and the names and
            significance of kinship relations like <span class="quote">“<span class="quote">is parent of</span>”</span> or <span class="quote">“<span class="quote">is sibling
                of</span>”</span> are familiar ones, making kinship a good starting point for understanding
                <span class="strong"><strong><a class="glossterm" href="go01.html#gloss_relationship"><em class="glossterm">relationships</em></a></strong></span> in organizing
                systems.<sup>[<a id="chapter-5-endnote-02" href="#ftn.chapter-5-endnote-02" class="footnote">254</a>]</sup> An organizing system can make use of existing relationships among resources,
            or it can create relationships by applying organizing principles to arrange the
            resources. Organizing systems for digital resources or digital description resources are
            the most likely to rely on explicit relationships to enable interactions with the
            resources.</p><p><a id="id622284" class="indexterm"/><a id="id622302" class="indexterm"/>In a classic book called <a class="link" href="bi01.html#Kent2012" title="Data and Reality: A Timeless Perspective on Perceiving and Managing Information in Our Imprecise World"><em class="citetitle">Data and Reality</em></a>, <span class="personname"><span class="firstname">William</span> <span class="surname">Kent</span></span> defines a <span class="strong"><strong><a class="glossterm" href="go01.html#gloss_relationship"><em class="glossterm">relationship</em></a></strong></span> as
                    <span class="quote">“<span class="quote"><span>an association among several things, with that association having
                    a particular significance</span>.</span>”</span><sup>[<a id="chapter-5-endnote-03" href="#ftn.chapter-5-endnote-03" epub:type="noteref" class="footnote">255</a>]</sup>
            <span class="quote">“<span class="quote">The things being associated,</span>”</span> the components of the relationship, are
            people in kinship relationships but more generally can be any type of resource (<a class="xref" href="ch03.html" title="Chapter 3. Resources in Organizing Systems">Chapter 3</a>), when we relate one resource instance to
            another. When we describe a resource (<a class="xref" href="ch04.html" title="Chapter 4. Resource Description and Metadata">Chapter 4</a>),
            the components of the relationship are a primary resource and a description resource. If
            we specify sets of relationships that go together, we are using these common
            relationships to define resource types or classes, which more generally are called
            categories (<a class="xref" href="ch06.html" title="Chapter 6. Categorization: Describing Resource Classes and Types">Chapter 6</a>). We can then use resource
            types as one or both the components of a relationship when we want to further describe
            the resource type or to assert how two resource types go together to facilitate our
            interactions with them.</p><p>We begin with a more complete definition of relationship and introduce five
            perspectives for analyzing them: semantic, lexical, structural, architectural, and
            implementation. We then discuss each perspective, introducing the issues that each emphasizes, and the
            specialized vocabulary needed to describe and analyze relationships from that point of
            view. We apply these perspectives and vocabulary to analyze the most important
            types of relationships in organizing systems.</p></div><div class="sect1" title="Describing Relationships: An Overview"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="section-5.2">Describing Relationships: An Overview</h2></div></div></div><p>The concept of a relationship is pervasive in human societies in both informal and
            formal senses. Humans are inescapably related to generations of ancestors, and in most
            cases they also have social networks of friends, co-workers, and casual acquaintances to
            whom they are related in various ways. We often hear that our access to information, money, jobs, and political power is all
            about <span class="quote">“<span class="quote">who you know,</span>”</span> so we strive to <span class="quote">“<span class="quote">network</span>”</span> with other
            people to build relationships that might help us expand our access. In information
            systems, relationships between resources embody the organization that enables
                <span class="action">finding</span>, <span class="action">selection</span>, <span class="action">retrieval</span>,
            and other interactions.</p><p><a id="id622547" class="indexterm"/>Most organizing systems are based on many relationships to enable the system
            to satisfy some intentional purposes with individual resources or the collection as a
            whole. In the domain of information resources, common resources include web pages,
            journal articles, books, data sets, metadata records, and <abbr class="abbrev">XML</abbr>
            documents, among many others. Important relationships in the information domain that
            facilitate purposes like finding, identifying, and selecting resources include <span class="quote">“<span class="quote">is
                the author of,</span>”</span> <span class="quote">“<span class="quote">is published by,</span>”</span> <span class="quote">“<span class="quote">has publication
                date,</span>”</span> <span class="quote">“<span class="quote">is derived from,</span>”</span> <span class="quote">“<span class="quote">has subject keyword,</span>”</span>
                <span class="quote">“<span class="quote">is related to,</span>”</span> and many others.</p><p>When we talk about relationships we specify both the resources that are associated
            along with a name or statement about the reason for the association. Just identifying
            the resources involved is not enough because several different relationships can exist
            among the same resources; the same person can be your brother, your employer, and your
            landlord. Furthermore, for many relationships the directionality or ordering of the
            participants in a relationship statement matters; the person who is your employer gives
            a paycheck to you, not vice versa. Kent points out that when we describe a relationship
            we sometimes use whole phrases, such as <span class="quote">“<span class="quote">is-employed-by,</span>”</span> if our language
            does not contain a single word that expresses the meaning of the relationship.</p><p>We can analyze relationships from several different perspectives: </p><div class="glosslist"><dl><dt>Semantic perspective</dt><dd><p><span><a id="def_semantic_perspective"/>The semantic perspective is the
                                most essential one; it characterizes the meaning of the association
                                between resources.</span></p></dd><dt>Lexical perspective</dt><dd><p><a id="id622618" class="indexterm"/><a id="id622629" class="indexterm"/><a id="id622642" class="indexterm"/><span><a id="def_lexical_perspective"/>The lexical perspective
                                focuses on how the conceptual description of a relationship is
                                expressed using words in a specific language.</span></p></dd><dt>Structural perspective</dt><dd><p><span><a id="def_structural_perspective"/>The structural perspective
                                analyzes the actual patterns of association, arrangement, proximity,
                                or connection between resources.</span></p></dd><dt>Architectural perspective</dt><dd><p><a id="id622715" class="indexterm"/><a id="id622721" class="indexterm"/><a id="id622736" class="indexterm"/><span><a id="def_architectural_perspective"/>The architectural
                                perspective emphasizes the number and abstraction level of the
                                components of a relationship, which together characterize its
                                complexity.</span></p></dd><dt>Implementation
                        perspective</dt><dd><p><a id="id622770" class="indexterm"/><a id="id622786" class="indexterm"/><span><a id="def_implementation_perspective"/>The
                                implementation perspective considers how the relationship is
                                implemented in a particular notation and syntax and the manner in
                                which relationships are arranged and stored in some technology
                                environment.</span></p></dd></dl></div><p>The remainder of this chapter is organized around a discussion of these five
            perspectives in the order listed here.</p></div><div class="sect1" title="The Semantic Perspective"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="section-5.3">The Semantic Perspective</h2></div></div></div><p>In order to describe relationships among resources, we need to understand what the
            relations mean. This <span class="bold"><strong><a class="glossterm" href="go01.html#gloss_semantic_perspective"><em class="glossterm">semantic
                    perspective</em></a></strong></span> is the essence of relationships and explains
            why the resources are related, relying on information that is not directly available
            from perceiving the resources.<sup>[<a id="chapter-5-endnote-04" href="#ftn.chapter-5-endnote-04" epub:type="noteref" class="footnote">256</a>]</sup> In our Simpson family example, we noted that Homer and Marge are related by
            marriage, and also by their relationship as parents of Bart, Lisa, and Maggie, and none
            of these relationships are directly perceivable.</p><p><a id="id622946" class="indexterm"/><a id="id622955" class="indexterm"/>Semantic relationships are commonly expressed with a predicate with one
            or more arguments. <span><a id="def_predicate"/>A <a class="glossterm" href="go01.html#gloss_predicate"><em class="glossterm">predicate</em></a> is a verb phrase template for specifying properties of
                objects or a relationship among objects.</span> In many relationships the
            predicate is an action or association that involves multiple participants that must be
            of particular types, and the arguments define the different roles of the
                participants.<sup>[<a id="chapter-5-endnote-05" href="#ftn.chapter-5-endnote-05" epub:type="noteref" class="footnote">257</a>]</sup></p><p><a id="id623034" class="indexterm"/><a id="id623046" class="indexterm"/>We can express the relationship between Homer and Marge Simpson using a
                <span class="emphasis"><em>predicate(argument(s))</em></span> syntax as follows:</p><div class="informalexample"><div class="literallayout"><p><br/>
    <span class="strong"><strong>is-married-to (Homer Simpson, Marge Simpson)</strong></span></p></div></div><p>The sequence, type, and role of the arguments are an essential part of the
            relationship expression. <a id="id623062" class="indexterm"/><a id="id623085" class="indexterm"/>The sequence and role are explicitly distinguished when predicates that take
            two arguments are expressed using a <span class="emphasis"><em>subject-predicate-object</em></span> syntax
            that is often called a <a class="glossterm" href="go01.html#gloss_triple"><em class="glossterm">triple</em></a> because of
            its three parts:</p><div class="informalexample"><div class="literallayout"><p><br/>
    <span class="strong"><strong>Homer Simpson <span class="symbol">→</span> is-married-to <span class="symbol">→</span> Marge Simpson</strong></span></p></div></div><p><a id="id623124" class="indexterm"/>However, we have not yet specified what the <span class="quote">“<span class="quote">is-married-to</span>”</span>
            relationship means. People can demonstrate their understanding of
                <span class="quote">“<span class="quote">is-married-to</span>”</span> by realizing that alternative and semantically
            equivalent expressions of the relationship between Homer and Marge might be:</p><div class="informalexample"><div class="literallayout"><p><br/>
    <span class="strong"><strong>Homer Simpson <span class="symbol">→</span> is-married-to <span class="symbol">→</span> Marge Simpson</strong></span><br/>
    <span class="strong"><strong>Homer Simpson <span class="symbol">→</span> is-the-husband-of <span class="symbol">→</span> Marge Simpson</strong></span><br/>
    <span class="strong"><strong>Marge Simpson <span class="symbol">→</span> is-married-to <span class="symbol">→</span> Homer Simpson</strong></span><br/>
    <span class="strong"><strong>Marge Simpson <span class="symbol">→</span> is-the-wife-of <span class="symbol">→</span> Homer Simpson</strong></span></p></div></div><p>Going one step further, we could say that people understand the equivalence of these
            different expressions of the relationship because they have semantic and linguistic
            knowledge that relates some representation of <span class="quote">“<span class="quote">married,</span>”</span>
            <span class="quote">“<span class="quote">husband,</span>”</span>
            <span class="quote">“<span class="quote">wife,</span>”</span> and other words. None of that knowledge is visible in the
            expressions of the relationships so far, all of which specify concrete relationships
            about individuals and not abstract relationships between resource classes or concepts.
            We have simply pushed the problem of what it means to understand the expressions into
            the mind of the person doing the understanding.</p><p>We can be more rigorous and define the words used in these expressions so they are
                <span class="quote">“<span class="quote">in the world</span>”</span> rather than just <span class="quote">“<span class="quote">in the mind</span>”</span> of the
            person understanding them. We can write definitions about these resource
                classes:<sup>[<a id="chapter-5-endnote-06" href="#ftn.chapter-5-endnote-06" epub:type="noteref" class="footnote">258</a>]</sup></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p><a id="id623254" class="indexterm"/><a id="id623263" class="indexterm"/>The conventional or traditional marriage relationship is a
                    consensual lifetime association between a husband and a wife, which is
                    sanctioned by law and often by religious ceremonies;</p></li><li class="listitem"><p><a id="id623294" class="indexterm"/>A husband is a male lifetime partner considered in relation to his
                    wife; and</p></li><li class="listitem"><p><a id="id623306" class="indexterm"/>A wife is a female lifetime partner considered in relation to her
                    husband.</p></li></ul></div><p>Definitions like these help a person learn and make some sense of the
            relationship expressions involving Homer and Marge. However, these definitions are not in a form that would enable someone to completely understand the Homer and Marge
            expressions; they rely on other undefined terms (consensual, law, lifetime, etc.), and
            they do not state the relationships among the concepts in the definitions.<sup>[<a id="chapter-5-endnote-07" href="#ftn.chapter-5-endnote-07" epub:type="noteref" class="footnote">259</a>]</sup> Furthermore, for a computer to understand the expressions, it needs a
            computer-processable representation of the relationships among words and meanings that
            makes every important semantic assumption and property precise and explicit. We will see
            what this takes starting in the next section.</p><div class="sect2" title="Types of Semantic Relationships"><div class="titlepage"><div><div><h3 class="title" id="section-5.3.1">Types of Semantic Relationships</h3></div></div></div><p>In this discussion we will use <span class="quote">“<span class="quote">entity type,</span>”</span>
                <span class="quote">“<span class="quote">class,</span>”</span>
                <span class="quote">“<span class="quote">concept,</span>”</span> and <span class="quote">“<span class="quote">resource type</span>”</span> as synonyms. <span class="bold"><strong><a class="glossterm" href="go01.html#gloss_entity_type"><em class="glossterm">Entity type</em></a></strong></span> and <span class="bold"><strong><a class="glossterm" href="go01.html#gloss_classes"><em class="glossterm">class</em></a></strong></span> are
                conventional terms in data modeling and database design, <span class="quote">“<span class="quote">concept</span>”</span> is the conventional term in computational or cognitive
                modeling, and we use <span class="quote">“<span class="quote">resource type</span>”</span>when we
                discuss organizing systems. Similarly, we will use <span class="quote">“<span class="quote">entity occurrence,</span>”</span>
                <span class="bold"><strong><a class="glossterm" href="go01.html#gloss_instance"><em class="glossterm">instance,</em></a></strong></span> and <span class="quote">“<span class="quote">resource
                    instance</span>”</span> when we refer to one thing rather than to a class or type of
                them.</p><p>There is no real consensus on how to categorize semantic relationships, but these
                three broad categories are reasonable for our purposes: </p><div class="glosslist"><dl><dt>Inclusion</dt><dd><p><a id="id623557" class="indexterm"/><a id="id623569" class="indexterm"/><span><a id="def_inclusion_relationship"/>One entity type
                                    contains or is comprised of other entity types; often expressed
                                    using <span class="quote">“<span class="quote">is-a,</span>”</span>
                                    <span class="quote">“<span class="quote">is-a-type-of,</span>”</span>
                                    <span class="quote">“<span class="quote">is-part-of,</span>”</span> or <span class="quote">“<span class="quote">is-in</span>”</span>
                                    predicates.</span></p></dd><dt>Attribution</dt><dd><p><span><a id="def_attribution"/><span class="action"><a id="id623629" class="indexterm"/>Asserting or assigning values to
                                        properties</span>; the predicate depends on the property:
                                        <span class="quote">“<span class="quote">is-the-author-of,</span>”</span>
                                    <span class="quote">“<span class="quote">is-married-to,</span>”</span>
                                    <span class="quote">“<span class="quote">is-employed-by,</span>”</span> etc.</span></p></dd><dt>Possession</dt><dd><p><a id="id623669" class="indexterm"/><a id="id623681" class="indexterm"/><span><a id="def_possession"/><span class="action">Asserting ownership
                                        or control</span> of a resource; often expressed using a
                                        <span class="quote">“<span class="quote">has</span>”</span> predicate, such as
                                        <span class="quote">“<span class="quote">has-serial-number-plate.</span>”</span></span><sup>[<a id="chapter-5-endnote-08" href="#ftn.chapter-5-endnote-08" epub:type="noteref" class="footnote">260</a>]</sup></p></dd></dl></div><p>All of these are fundamental in organizing systems, both for describing and
                arranging resources themselves, and for describing the relationships among resources
                and resource descriptions.</p><div class="sect3" title="Inclusion"><div class="titlepage"><div><div><h4 class="title" id="section-5.3.1.1">Inclusion</h4></div></div></div><p>There are three different types of inclusion relationships: class inclusion,
                    meronymic inclusion, and topological inclusion. All three are commonly used in
                    organizing systems.</p><p><span class="strong"><strong><a class="glossterm" href="go01.html#gloss_class_inclusion"><em class="glossterm">Class
                        Inclusion</em></a></strong></span><span><a id="def_class_inclusion"/> is the
                        fundamental and familiar <span class="quote">“<span class="quote"><span class="strong"><strong>is-a,</strong></span></span>”</span>
                        <span class="quote">“<span class="quote"><span class="strong"><strong>is-a-type-of</strong></span>,</span>”</span> or
                                <span class="quote">“<span class="quote"><span class="strong"><strong>subset</strong></span></span>”</span>
                        relationship between two entity types or classes where one is contained in
                        and thus more specific than the other more generic one.</span></p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Meat <span class="symbol">→</span> is-a <span class="symbol">→</span> Food</strong></span></p></div></div><p><a id="id623865" class="indexterm"/>A set of interconnected class inclusion relationships creates a
                    hierarchy, which is often called a <span class="strong"><strong><a class="glossterm" href="go01.html#gloss_taxonomy"><em class="glossterm">taxonomy</em></a></strong></span>.</p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Meat <span class="symbol">→</span> is-a <span class="symbol">→</span> Food</strong></span><br/>
        <span class="strong"><strong>Dairy Product <span class="symbol">→</span> is-a <span class="symbol">→</span> Food</strong></span><br/>
        <span class="strong"><strong>Cereal <span class="symbol">→</span> is-a <span class="symbol">→</span> Food</strong></span><br/>
        <span class="strong"><strong>Vegetable <span class="symbol">→</span> is-a <span class="symbol">→</span> Food</strong></span><br/>
        <span class="strong"><strong>Beef <span class="symbol">→</span> is-a <span class="symbol">→</span> Meat</strong></span>    <br/>
        <span class="strong"><strong>Pork <span class="symbol">→</span> is-a <span class="symbol">→</span> Meat</strong></span><br/>
        <span class="strong"><strong>Chicken <span class="symbol">→</span> is-a <span class="symbol">→</span> Meat</strong></span><br/>
        <span class="strong"><strong>Ground Beef <span class="symbol">→</span> is-a <span class="symbol">→</span> Beef</strong></span><br/>
        <span class="strong"><strong>Steak <span class="symbol">→</span> is-a <span class="symbol">→</span> Beef</strong></span><br/>
        <span class="strong"><strong>...</strong></span></p></div></div><p>A visual depiction of the taxonomy makes the class hierarchy easier to
                    perceive. See <a class="xref" href="ch05.html#chapter-5-figure-5.1" title="Figure 5-1. A Partial Taxonomy of Food.">Figure 5-1</a></p><div class="figure-float"><div class="figure"><a id="chapter-5-figure-5.1"/><div class="figure-contents"><div class="mediaobject"><a id="chapter-5-figure-5.1a"/><img src="figs/print/ch5.1-350dpi.png" alt="A partial taxonomy of food distinguishes the categories or prepared food from meat, &#10;                            distinguishes chicken, beef, and pork as subcategories of meat, and distinguishes ground beef and steak &#10;                            as some of the subcategories of the beef category."/></div></div><div class="figure-title">Figure 5-1. A Partial Taxonomy of Food.</div></div></div><p>Each level in a taxonomy subdivides the class above it into sub-classes, and
                    each sub-class is further subdivided until the differences that remain among the
                    members of each class no longer matter for the interactions the organizing
                    system needs to support. We discuss the design of hierarchical organizing
                    systems in <a class="xref" href="ch06.html#section-6.3" title="Principles for Creating Categories">Principles for Creating Categories</a>, <span class="quote">“<span class="quote">Principles
                        for Creating Categories.</span>”</span></p><p>All of the examples in the current section have expressed abstract
                    relationships between classes, in contrast to the earlier concrete ones about
                    Homer and Marge, which expressed relationships between specific people. Homer
                    and Marge are instances of classes like <span class="quote">“<span class="quote">married people,</span>”</span>
                    <span class="quote">“<span class="quote">husbands,</span>”</span> and <span class="quote">“<span class="quote">wives.</span>”</span>
                    <a id="id624126" class="indexterm"/><a id="id624131" class="indexterm"/>
                    <span><a id="def_classifying"/>When we make an assertion that a particular
                        instance is a member of class, we are <span class="strong"><strong><a class="glossterm" href="go01.html#gloss_classifying"><em class="glossterm">classifying</em></a></strong></span> the instance.</span>
                    <span><span class="strong"><strong><a class="glossterm" href="go01.html#gloss_classification"><em class="glossterm">Classification</em></a></strong></span> is a class inclusion
                        relationship between an instance and a class rather than between two
                        classes.</span> (We discuss Classification in detail in <a class="xref" href="ch07.html" title="Chapter 7. Classification: Assigning Resources to Categories">Chapter 7</a>).</p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Homer Simpson <span class="symbol">→</span> is-a <span class="symbol">→</span> Husband</strong></span></p></div></div><p>This is just the lowest level of the class hierarchy in which Homer is located
                    at the very bottom; he is also a man, a human being, and a living organism (in
                    cartoon land, at least).<sup>[<a id="chapter-5-endnote-09" href="#ftn.chapter-5-endnote-09" epub:type="noteref" class="footnote">261</a>]</sup> You might now remember the bibliographic class inclusion hierarchy
                    we discussed in <a class="xref" href="ch03.html#section-3.3.2" title="Identity and Bibliographic Resources">Identity and Bibliographic Resources</a>; a specific physical <span class="strong"><strong><a class="glossterm" href="go01.html#gloss_item"><em class="glossterm">item</em></a></strong></span> like your dog-eared copy of
                        <em class="citetitle">Macbeth</em> is also a particular <span class="strong"><strong>manifestation</strong></span> in some format or genre, and this <span class="strong"><strong><a class="glossterm" href="go01.html#gloss_expression"><em class="glossterm">expression</em></a></strong></span> is one of many for the abstract
                        <span class="strong"><strong>work</strong></span>.</p><p><span><a id="def_part-whole_inclusion"/><span class="strong"><strong><a class="glossterm" id="term_part-whole_inclusion" href="go01.html#gloss_part-whole_inclusion"><em class="glossterm">Part-whole inclusion</em></a></strong></span> or <span class="strong"><strong><a class="glossterm" href="go01.html#gloss_meronymic_inclusion"><em class="glossterm">meronymic
                                inclusion</em></a></strong></span> is a second type of inclusion
                        relationship. It is usually expressed using <span class="quote">“<span class="quote">is-part-of,</span>”</span>
                        <span class="quote">“<span class="quote">is-partly,</span>”</span> or with other similar predicate
                        expressions.</span> Winston, Chaffin, and Herrmann identified six distinct
                    types of part-whole relationships:<sup>[<a id="chapter-5-endnote-10" href="#ftn.chapter-5-endnote-10" epub:type="noteref" class="footnote">262</a>]</sup></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: none"><p><a id="id624340" class="indexterm"/><a id="id624354" class="indexterm"/><span><a id="def_component-object_inclusion"/><em class="glossterm">Component-Object</em> is the relationship
                                type when the part is a separate component that is arranged or
                                assembled with other components to create a larger
                                resource.</span> In <a class="xref" href="ch03.html#section-3.1.1.1" title="Resources with Parts">Resources with Parts</a>, <span class="quote">“<span class="quote">Resources with Parts,</span>”</span> we used as
                            an example the component-object relationship between an engine and a
                            car:</p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>The Engine <span class="symbol">→</span> is-part-of <span class="symbol">→</span> the Car</strong></span></p></div></div><p>The components of this type of part-whole relationship need not be
                            physical objects; <span class="quote">“<span class="quote">Germany is part of the European Union</span>”</span>
                            expresses a component-object relationship. What matters is that the
                            component is identifiable on its own as an integral entity and that the
                            components follow some kind of patterned organization or structure when
                            they form the whole. Together the parts form a composition, and the
                            parts collectively form the whole. A car that lacks the engine part will
                            not work.</p></li><li class="listitem" style="list-style-type: none"><p><a id="id624424" class="indexterm"/><a id="id624445" class="indexterm"/><span><a id="def_member-collection_inclusion"/><a class="glossterm" id="term_member-collection_inclusion" href="go01.html#gloss_member-collection_inclusion"><em class="glossterm">Member-Collection</em></a> is the part-whole relationship
                                type where <span class="quote">“<span class="quote">is-part-of</span>”</span> means
                                    <span class="quote">“<span class="quote">belongs-to,</span>”</span> a weaker kind of association than
                                component-object because there is no assumption that the component
                                has a specific role or function in the whole. </span></p><div class="informalexample"><div class="literallayout"><p>         <span class="strong"><strong>The Book <span class="symbol">→</span> is-part-of <span class="symbol">→</span> the Library</strong></span></p></div></div><p>The members of the collection exist independently of the whole; if the
                            whole ceases to exist the individual resources still exist. </p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>The Slice <span class="symbol">→</span> is-part-of <span class="symbol">→</span> the Pie</strong></span></p></div></div></li><li class="listitem" style="list-style-type: none"><p><span><a id="def_portion-mass_inclusion"/><a class="glossterm" id="term_portion-mass_inclusion" href="go01.html#gloss_portion-mass_inclusion"><em class="glossterm">Portion-Mass</em></a> is the
                                relationship type when all the parts are similar to each other and
                                to the whole, unlike either of the previous types where engines are
                                not tires or cars, and books are not like record albums or
                                libraries.</span></p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>The Slice <span class="symbol">→</span> is-part-of <span class="symbol">→</span> the Pie</strong></span></p></div></div></li><li class="listitem" style="list-style-type: none"><p><a id="id624578" class="indexterm"/><a id="id624569" class="indexterm"/><span><a id="def_stuff-object_inclusion"/><a class="glossterm" id="term_stuff-object_inclusion" href="go01.html#gloss_stuff-object_inclusion"><em class="glossterm">Stuff-Object</em></a>
                                relationships are most often expressed using
                                    <span class="quote">“<span class="quote">is-partly</span>”</span> or <span class="quote">“<span class="quote">is-made-of</span>”</span> and are
                                distinguishable from component-object ones because the stuff cannot
                                be separated from the object without altering its identity. The
                                stuff is not a separate ingredient that is used to make the object;
                                it is a constituent of it once it is made. </span></p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Wine <span class="symbol">→</span> is-partly <span class="symbol">→</span> Alcohol</strong></span> </p></div></div></li><li class="listitem" style="list-style-type: none"><p><a id="id624661" class="indexterm"/><a id="id624655" class="indexterm"/><span><a id="def_place-area_inclusion"/><a class="glossterm" id="term_place-area_inclusion" href="go01.html#gloss_place-area_inclusion"><em class="glossterm">Place-Area</em></a>
                                relationships exist between areas and specific places or locations
                                within them. Like members of collections, places have no particular
                                functional contribution to the whole. </span></p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>The Everglades <span class="symbol">→</span> are-part-of <span class="symbol">→</span> Florida</strong></span></p></div></div></li><li class="listitem" style="list-style-type: none"><p><a id="id624684" class="indexterm"/><a id="id624727" class="indexterm"/><span><a id="def_feature-activity_inclusion"/><a class="glossterm" id="term_feature-activity_inclusion" href="go01.html#gloss_feature-activity_inclusion"><em class="glossterm">Feature-Activity</em></a> is a relationship type in which
                                the components are stages, phases, or sub activities that take place
                                over time. This relationship is similar to component-object in that
                                the components in the whole are arranged according to a structure or
                                pattern. </span></p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Overtime <span class="symbol">→</span> is-part-of <span class="symbol">→</span> a Football Game</strong></span></p></div></div></li></ul></div><div class="itemizedlist"><p>A seventh type of part-whole relationship called <a class="glossterm" href="go01.html#gloss_phase-activity_inclusion"><em class="glossterm">Phase-Activity</em></a> was
                        proposed by Storey.<sup>[<a id="chapter-5-endnote-11" href="#ftn.chapter-5-endnote-11" epub:type="noteref" class="footnote">263</a>]</sup></p><ul class="itemizedlist"><li class="listitem"><p><a id="id624809" class="indexterm"/><a id="id624822" class="indexterm"/><span><a id="def_phase-activity_inclusion"/><a class="glossterm" id="term_phase-activity_inclusion" href="go01.html#gloss_phase-activity_inclusion"><em class="glossterm">Phase-Activity</em></a> is
                                similar to <a class="glossterm" href="go01.html#gloss_feature-activity_inclusion"><em class="glossterm">feature-activity</em></a> except that the phases do not make
                                sense as standalone activities without the context provided by the
                                activity as a whole.</span></p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Paying <span class="symbol">→</span> is-part-of <span class="symbol">→</span> Shopping</strong></span></p></div></div></li></ul></div><p><span class="bold"><strong><em class="glossterm">Topological</em>,
                            <em class="glossterm">Locative</em> and <em class="glossterm">Temporal Inclusion</em></strong></span> is a third type
                    of <em class="glossterm">inclusion relationship</em> between a
                    container, area, or temporal duration and what it surrounds or contains. It is
                    most often expressed using <span class="quote">“<span class="quote">is-in</span>”</span> as the relationship. However,
                    the entity that is contained or surrounded is not a part of the including one,
                    so this is not a <a class="glossterm" href="go01.html#gloss_part-whole_inclusion"><em class="glossterm">part-whole</em></a> relationship.</p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>The Vatican City <span class="symbol">→</span> is-in <span class="symbol">→</span> Italy</strong></span><br/>
        <span class="strong"><strong>The meeting <span class="symbol">→</span> is-in <span class="symbol">→</span> the afternoon</strong></span><br/>
</p></div></div></div><div class="sect3" title="Attribution"><div class="titlepage"><div><div><h4 class="title" id="section-5.3.1.2">Attribution</h4></div></div></div><p>In contrast to inclusion expressions that state relationships between
                    resources, <em class="glossterm">attribution</em> relationships assert
                    or assign values to properties for a particular resource. In <a class="xref" href="ch04.html" title="Chapter 4. Resource Description and Metadata">Chapter 4</a> we used <span class="quote">“<span class="quote">attribute</span>”</span> to
                    mean <span class="quote">“<span class="quote">an indivisible part of a resource description</span>”</span> and treated it
                    as a synonym of <span class="quote">“<span class="quote">property.</span>”</span>
                    <span>We now need to be more precise and carefully distinguish between the
                        type of the <a class="glossterm" href="go01.html#gloss_attribute"><em class="glossterm">attribute</em></a> and the <a class="glossterm" href="go01.html#gloss_value"><em class="glossterm">value</em></a> that it has. For example, the color
                        of any object is an <a class="glossterm" href="go01.html#gloss_attribute"><em class="glossterm">attribute</em></a> of the object, and the <span class="italic">value</span> of that attribute might be
                        <span class="quote">“<span class="quote">green.</span>”</span></span></p><p>Some frameworks for semantic modeling define <span class="quote">“<span class="quote">attribute</span>”</span> very
                    narrowly, restricting it to expressions with predicates with only one argument
                    to assert properties of a single resource, distinguishing them from
                    relationships between resources or resource types that require two
                        arguments:<sup>[<a id="chapter-5-endnote-12" href="#ftn.chapter-5-endnote-12" class="footnote">264</a>]</sup></p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Martin the Gecko <span class="symbol">→</span> is-small</strong></span><br/>
        <span class="strong"><strong>Martin the Gecko <span class="symbol">→</span> is-green</strong></span> </p></div></div><p>However, it is always possible to express statements like these in ways that
                    make them into relationships with two arguments:</p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Martin <span class="symbol">→</span> has-size <span class="symbol">→</span> small</strong></span><br/>
        <span class="strong"><strong>Martin <span class="symbol">→</span> has-skin-color <span class="symbol">→</span> green</strong></span> </p></div></div><p><span class="personname"><span class="firstname">Dedre</span> <span class="surname">Gentner</span></span> notes that this supposed distinction between one-predicate
                    attributes and two-predicate relationships depends on context.<sup>[<a id="chapter-5-endnote-13" href="#ftn.chapter-5-endnote-13" epub:type="noteref" class="footnote">265</a>]</sup> For example, small can be viewed as an attribute, <span class="strong"><strong>X <span class="symbol">→</span> is-small,</strong></span> or as a
                    relationship between X and some standard or reference Y, <span class="strong"><strong>X <span class="symbol">→</span> is-smaller-than <span class="symbol">→</span>
                        Y.</strong></span></p><p>Another somewhat tricky aspect of attribution relationships is that from a
                    semantic perspective, there are often many different ways of expressing
                    equivalent attribute values.</p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Martin <span class="symbol">→</span> has-size <span class="symbol">→</span> 6 inches</strong></span><br/>
        <span class="strong"><strong>Martin <span class="symbol">→</span> has size <span class="symbol">→</span> 152 mm</strong></span>        </p></div></div><p>These two statements express the idea that Martin is small. However,
                    many implementations of attribution relationships treat the attribute values
                    literally. This means that unless we can process these two statements using another relationship that expresses the conversion of inches to mm,
                    the two statements could be interpreted as saying different things about Martin’s
                    size.</p><p>Finally, we note that we can express attribution relationships about other
                    relationships, like the date a relationship was established. Homer and Marge
                    Simpson’s wedding anniversary is an attribute of their
                        <span class="quote">“<span class="quote">is-married-to</span>”</span> relationship.</p><p>The semantic distinctions between attributes and other types of relationships
                    are not strong ones, but they can be made clearer by implementation choices. For
                    example, <abbr class="abbrev">XML</abbr> attributes are tightly coupled to a containing
                    element, and their literal values are limited to atomic items of information. In
                    contrast, inclusion relationships are expressed by literal containment of one
                        <abbr class="abbrev">XML</abbr> element by another.</p></div><div class="sect3" title="Possession"><div class="titlepage"><div><div><h4 class="title" id="section-5.3.1.3">Possession</h4></div></div></div><p>A third distinct category of semantic relationships is that of possession.
                        <em class="glossterm">Possession</em> relationships can seem
                    superficially like part-whole ones:</p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Bob <span class="symbol">→</span> has <span class="symbol">→</span> a car</strong></span><br/>
        <span class="strong"><strong>A car <span class="symbol">→</span> has <span class="symbol">→</span> wheels</strong></span></p></div></div><p>However, in the second of these relationships <span class="quote">“<span class="quote">has</span>”</span> is an
                    elliptical form of <span class="quote">“<span class="quote">has as a part,</span>”</span> expressing a component-object
                    relationship rather that one of possession.</p><p>The concept of possession is especially important in institutional organizing
                    systems, where questions of ownership, control, responsibility and transfers of
                    ownership, control, and responsibility can be fundamental parts of the
                    interactions they support. However, possession is a complex notion, inherently
                    connected to societal norms and conventions about property and kinship, making
                    it messier than institutional processes might like. Possession relationships
                    also imply duration or persistence, and are often difficult to distinguish from
                    relationships based on habitual location or practice. Miller and Johnson-Laird
                    illustrate the complex nature of possession relationships with this sentence,
                    which expresses three different types of them:<sup>[<a id="chapter-5-endnote-14" href="#ftn.chapter-5-endnote-14" epub:type="noteref" class="footnote">266</a>]</sup></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: none"><p><span class="strong"><strong>He owns an umbrella but she’s borrowed it,
                                though she doesn’t have it with her.</strong></span></p></li></ul></div></div></div><div class="sect2" title="Properties of Semantic Relationships"><div class="titlepage"><div><div><h3 class="title" id="section-5.3.2">Properties of Semantic Relationships</h3></div></div></div><p>Semantic relationships can have numerous special properties that help explain what
                they mean and especially how they relate to each other. In the following sections we
                briefly explain those that are most important in systems for organizing resources
                and resource descriptions.</p><div class="sect3" title="Symmetry"><div class="titlepage"><div><div><h4 class="title" id="section-5.3.2.1">Symmetry</h4></div></div></div><p>In most relationships the order in which the subject and object arguments are
                    expressed is central to the meaning of the relationship. If X has a relationship
                    with Y, it is usually not the case that Y has the same relationship with X. For
                    example, because <span class="quote">“<span class="quote">is-parent-of</span>”</span> is an <em class="glossterm">asymmetric</em> relationship, only the first of these relationships
                    holds:</p><div class="informalexample"><div class="literallayout"><p><br/>
    <span class="strong"><strong>Homer Simpson <span class="symbol">→</span> is-parent-of <span class="symbol">→</span> Bart Simpson (<code class="literal">TRUE</code>)</strong></span><br/>
    <span class="strong"><strong>Bart Simpson <span class="symbol">→</span> is-parent-of <span class="symbol">→</span> Homer Simpson (<code class="literal">NOT TRUE</code>)</strong></span>       </p></div></div><p>In contrast, some relationships are <em class="glossterm">symmetric</em> or <a class="glossterm" href="go01.html#gloss_bi-directional"><em class="glossterm">bi-directional</em></a>, and reversing the
                    order of the arguments of the relationship predicate does not change the
                    meaning. As we noted earlier, these two statements are semantically equivalent
                    because <span class="quote">“<span class="quote">is-married-to</span>”</span> is symmetric:</p><div class="informalexample"><div class="literallayout"><p>    <span class="strong"><strong>Homer Simpson <span class="symbol">→</span> is-married-to <span class="symbol">→</span> Marge Simpson</strong></span><br/>
    <span class="strong"><strong>Marge Simpson <span class="symbol">→</span> is-married-to <span class="symbol">→</span> Homer Simpson</strong></span>                   </p></div></div><p>We can represent the <span class="strong"><strong>symmetric</strong></span> and
                        <span class="strong"><strong><a class="glossterm" href="go01.html#gloss_bi-directional"><em class="glossterm">bi-directional</em></a></strong></span> nature
                    of these relationships by using a double-headed arrow:</p><div class="informalexample"><div class="literallayout"><p>    <span class="strong"><strong>Homer Simpson <span class="symbol">⇔</span> is-married-to <span class="symbol">⇔</span> Marge Simpson</strong></span>        </p></div></div></div><div class="sect3" title="Transitivity"><div class="titlepage"><div><div><h4 class="title" id="section-5.3.2.2">Transitivity</h4></div></div></div><p><em class="glossterm">Transitivity</em> is another property that can
                    apply to semantic relationships. When a relationship is transitive, if X and Y
                    have a relationship, and Y and Z have the same relationship, then X also has the
                    relationship with Z. Any relationship based on ordering is transitive, which
                    includes numerical, alphabetic, and chronological ones as well as those that
                    imply qualitative or quantitative measurement. Because
                        <span class="quote">“<span class="quote">is-taller-than</span>”</span> is transitive:</p><div class="informalexample"><div class="literallayout"><p>    <span class="strong"><strong>Homer Simpson <span class="symbol">→</span> is-taller-than <span class="symbol">→</span> Bart Simpson</strong></span><br/>
    <span class="strong"><strong>Bart Simpson <span class="symbol">→</span> is-taller-than <span class="symbol">→</span> Maggie Simpson</strong></span>                   </p></div></div><p>implies that:</p><div class="informalexample"><div class="literallayout"><p>    <span class="strong"><strong>Homer Simpson <span class="symbol">→</span> is-taller-than <span class="symbol">→</span> Maggie Simpson</strong></span>        </p></div></div><p>Inclusion relationships are inherently transitive, because just as
                        <span class="quote">“<span class="quote">is-taller-than</span>”</span> is an assertion about relative physical size,
                        <span class="quote">“<span class="quote">is-a-type of</span>”</span> and <span class="quote">“<span class="quote">is-part-of</span>”</span> are assertions
                    about the relative sizes of abstract classes or categories.<sup>[<a id="chapter-5-endnote-15" href="#ftn.chapter-5-endnote-15" epub:type="noteref" class="footnote">267</a>]</sup></p><p><a id="id625864" class="indexterm"/>Transitive relationships enable inferences about class membership or
                    properties, and allow organizing systems to be more efficient in how they
                    represent them since transitivity enables implicit relationships to be made
                    explicit only when they are needed.</p></div><div class="sect3" title="Equivalence"><div class="titlepage"><div><div><h4 class="title" id="section-5.3.2.3">Equivalence</h4></div></div></div><p><a id="id625820" class="indexterm"/><a id="id625800" class="indexterm"/><span><a id="def_equivalence_relationship"/>Any relationship that is
                        both symmetric and transitive is an <em class="glossterm">equivalence</em> relationship; <span class="quote">“<span class="quote">is-equal-to</span>”</span> is
                        obviously an equivalence relationship because if A=B then B=A and if A=B and
                        B=C, then A=C. Other relationships can be equivalent without meaning
                            <span class="quote">“<span class="quote">exactly equal,</span>”</span> as is the relationship of
                            <span class="quote">“<span class="quote">is-congruent-to</span>”</span> for all triangles.</span></p><p>We often need to assert that a particular class or property has the same
                    meaning as another class or property or that it is generally <a id="id625889" class="indexterm"/> substitutable for it. We make this explicit with an equivalence
                    relationship.</p><div class="informalexample"><div class="literallayout"><p><span class="strong"><strong>Sister (English) <span class="symbol">⇔</span> is-equivalent-to <span class="symbol">⇔</span> Hermana (Spanish)</strong></span><br/>
<span class="strong"><strong>Sister (English) <span class="symbol">⇔</span> is-equivalent-to <span class="symbol">⇔</span> Hermana (Spanish)</strong></span>           <br/>
        </p></div></div></div><div class="sect3" title="Inverse"><div class="titlepage"><div><div><h4 class="title" id="section-5.3.2.4">Inverse</h4></div></div></div><p><a id="id625963" class="indexterm"/><a id="id625972" class="indexterm"/><span><a id="def_inverse_relationships"/>For asymmetric relationships,
                        it is often useful to be explicit about the meaning of the relationship when
                        the order of the arguments in the relationship is reversed. The resulting
                        relationship is called the <span class="bold"><strong><a class="glossterm" id="term_inverse_relationships" href="go01.html#gloss_inverse_relationships"><em class="glossterm">inverse</em></a></strong></span>
                        or the converse of the first relationship.</span> If an organizing system
                    explicitly represents that:</p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Is-child-of <span class="symbol">→</span> is-the-inverse-of <span class="symbol">→</span> Is-parent-of</strong></span>        </p></div></div><p>We can then conclude that:</p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Bart Simpson <span class="symbol">→</span> is-child-of <span class="symbol">→</span> Homer Simpson</strong></span>        .</p></div></div></div></div><div class="sect2" title="Ontologies"><div class="titlepage"><div><div><h3 class="title" id="section-5.3.3">Ontologies</h3></div></div></div><p>We now have described types and properties of semantic relationships in enough
                detail to return to the challenge we posed earlier: what information is required to fully
                understand relationships? This question has been asked and debated for decades and
                we will not pretend to answer it to any extent here. However, we can sketch out some
                of the basic parts of the solution.</p><p>Let us begin by recalling that a <a class="glossterm" href="go01.html#gloss_taxonomy"><em class="glossterm">taxonomy</em></a> captures a system of class inclusion
                relationships in some domain. But as we have seen, there are a great many kinds of
                relationships that are not about class inclusion. All of these other types of
                relationships represent knowledge about the domain that is potentially needed to
                understand statements about it and to make sense when more than one domain of
                resources or activities comes together.</p><p>For example, in the food domain whose partial taxonomy appears in <a class="xref" href="ch05.html#section-5.3.1" title="Types of Semantic Relationships">Types of Semantic Relationships</a>, we can assert relationships about properties of
                classes and instances, express equivalences about them, and otherwise enhance the
                representation of the food domain to create a complex network of relationships. In
                addition, the food domain intersects with food preparation, agriculture, commerce,
                and many other domains. We also need to express the relationships among these
                domains to fully understand any of them.</p><div class="informalexample"><div class="literallayout"><p><span class="strong"><strong><br/>
        Hamburger <span class="symbol">→</span> is-equivalent-to <span class="symbol">→</span> Ground Beef<br/>
        Hamburger <span class="symbol">→</span> is-prepared-by <span class="symbol">→</span> Grilling<br/>
        Grilling <span class="symbol">→</span> is-a-type-of <span class="symbol">→</span> Food Preparation<br/>
        Hamburger Sandwich <span class="symbol">→</span> is-a-type-of <span class="symbol">→</span> Prepared Food<br/>
        BigMac <span class="symbol">→</span> is-a <span class="symbol">→</span> Hamburger Sandwich<br/>
        A bun <span class="symbol">→</span> is-part-of <span class="symbol">→</span> Hamburger Sandwich<br/>
        A bun <span class="symbol">→</span> is-partly <span class="symbol">→</span> flour<br/>
        Temperature <span class="symbol">→</span> is-a-measure-of <span class="symbol">→</span> Grilling<br/>
        Rare <span class="symbol">→</span> is-a <span class="symbol">→</span> State of Food Preparation<br/>
        Well-done <span class="symbol">→</span> is-a <span class="symbol">→</span> State of Food Preparation<br/>
        Meat <span class="symbol">→</span> is-preserved-by <span class="symbol">→</span> Freezing<br/>
        Thawing <span class="symbol">→</span> is-the-inverse-of <span class="symbol">→</span> Freezing<br/>
        ...</strong></span><br/>
        </p></div></div><p>In this simple example we see that class inclusion relationships form a kind of
                backbone to which other kinds of relationships attach. We also see that
                there are many potentially relevant assertions that together represent
                the knowledge that just about everyone knows about food and related domains. A
                network of relationships like these creates a resource that is called an <a class="glossterm" href="go01.html#gloss_ontology"><em class="glossterm">ontology</em></a>.<sup>[<a id="chapter-5-endnote-16" href="#ftn.chapter-5-endnote-16" epub:type="noteref" class="footnote">268</a>]</sup> A visual depiction of the ontology illustrates this idea that it
                has a taxonomy as its conceptual scaffold. See <a class="xref" href="ch05.html#chapter-5-figure-5.3.3a" title="Figure 5-2. A Partial Ontology of Food.">Figure 5-2</a></p><div class="figure-float"><div class="figure"><a id="chapter-5-figure-5.3.3a"/><div class="figure-contents"><div class="mediaobject"><img src="figs/print/ucb-tdo-chapter5.3.3-ontology-color.png" alt="A partial ontology of food overlays the taxonomy of food with statements that make assertions &#10;                        about categories, instances, and relationships in the food domain.  &#10;                        Example statements might be that “Grilling is a type of food preparation,” &#10;                        that “Meat is preserved by freezing,” and that “Hamburger is equivalent to ground beef”."/></div></div><div class="figure-title">Figure 5-2. A Partial Ontology of Food.</div></div></div><p>
                <a id="id626399" class="indexterm"/><a id="id626412" class="indexterm"/><a id="id626417" class="indexterm"/> There are numerous formats for expressing ontologies, but many of them
                have recently converged to or are based on the <em class="firstterm"><a id="first_OWL"/><span class="citerefentry"><span class="refentrytitle">Web Ontology Language</span>(OWL)</span></em>, the developed by the <abbr class="abbrev">W3C</abbr>.
                    <abbr class="abbrev">OWL</abbr> ontologies use a formal logic-based language that builds on
                    <abbr class="abbrev">RDF</abbr> (<a class="xref" href="ch04.html#section-4.2.2.3" title="Tagging of Web-Based Resources">Tagging of Web-Based Resources</a>) to define resource
                classes and assign properties to them in rigorous ways, arrange them in a class
                hierarchy, establish their equivalence, and specify the properties of
                    relationships.<sup>[<a id="chapter-5-endnote-17" href="#ftn.chapter-5-endnote-17" class="footnote">269</a>]</sup></p><p>Ontologies are essential parts in some organizing systems, especially
                information-intensive ones where the scope and scale of the resources require an
                extensive and controlled description vocabulary (See <a class="xref" href="ch04.html#section-4.3" title="The Process of Describing Resources">The Process of Describing Resources</a>). <a id="id626470" class="indexterm"/><a id="id626475" class="indexterm"/>The most extensive ontology ever created is Cyc, born in 1984 as an
                artificial intelligence research project. Three decades later, the latest version of
                the Cyc ontology contains several hundred thousand terms and millions of assertions
                that interrelate them.<sup>[<a id="chapter-5-endnote-18" href="#ftn.chapter-5-endnote-18" class="footnote">270</a>]</sup></p></div></div><div class="sect1" title="The Lexical Perspective"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="section-5.4">The Lexical Perspective</h2></div></div></div><p>The semantic perspective for analyzing relationships is the fundamental one, but it is
            intrinsically tied to the lexical one because a relationship is always expressed using
            words in a specific language. For example, we understand the relationships among the
            concepts or classes of <span class="quote">“<span class="quote">food,</span>”</span>
            <span class="quote">“<span class="quote">meat,</span>”</span> and <span class="quote">“<span class="quote">beef</span>”</span> by using the words <span class="quote">“<span class="quote">food,</span>”</span>
            <span class="quote">“<span class="quote">meat,</span>”</span> and <span class="quote">“<span class="quote">beef</span>”</span> to identify progressively smaller classes
            of edible things in a class hierarchy.</p><p>The connection between concept and words is not so simple. In the Simpson family
            example with which we began this chapter, we noted with
                <span class="quote">“<span class="quote">father</span>”</span> and <span class="quote">“<span class="quote">padre</span>”</span> that languages differ in the words
            they use to describe particular kinship relationships. Furthermore, we pointed out that
            cultures differ in which kinship relationships are conceptually distinct, so that
            languages like Chinese make distinctions about the relative ages of siblings that are
            not made in English.<sup>[<a id="chapter-5-endnote-19" href="#ftn.chapter-5-endnote-19" epub:type="noteref" class="footnote">271</a>]</sup> This is not to suggest that an English speaker cannot notice the difference
            between his older and younger sisters, only that this distinction 
            is not lexicalized<span class="symbol">—</span>captured in a single word<span class="symbol">—</span>as it is
            in Chinese. <a id="id626642" class="indexterm"/>This <span class="quote">“<span class="quote">missing word</span>”</span> in English from the perspective of Chinese
            is called a <span class="quote">“<span class="quote">lexical gap.</span>”</span><sup>[<a id="chapter-5-endnote-20" href="#ftn.chapter-5-endnote-20" epub:type="noteref" class="footnote">272</a>]</sup></p><p>Earlier in this book we discussed the naming of resources (<a class="xref" href="ch03.html#section-3.4.2" title="The Problems of Naming">The Problems of Naming</a>) and the design of a vocabulary for resource description
                (<a class="xref" href="ch04.html#section-4.3.1.3" title="Scope, Scale, and Resource Description">Scope, Scale, and Resource Description</a>), and we explained how increasing the scope and
            scale of an organizing system made it essential to be more systematic and precise in
            assigning names and descriptions. We need to be sure that the terms we use to organize
            resources capture the similarities and differences between them well enough to support
            our interactions with them. After our discussion about semantic relationships in this
            chapter, we now have a clearer sense of what is required to bring like things together,
            keep different things separate, and to satisfy any other goals for the organizing
            system.</p><p>For example, if we are organizing cars, buses, bicycles, and sleds, all of which are
            vehicles, there is an important distinction between vehicles that are motorized and
            those that are powered by human effort. It might also be useful to distinguish vehicles
            with wheels from those that lack them. Not making these distinctions leaves an
            unbalanced or uneven organizing system for describing the semantics of the vehicle
            domain. However, only the <span class="quote">“<span class="quote">motorized</span>”</span> concept is lexicalized in English,
            which is why we needed to invent the <span class="quote">“<span class="quote">wheeled vehicle</span>”</span> term in the second
                case.<sup>[<a id="chapter-5-endnote-21" href="#ftn.chapter-5-endnote-21" epub:type="noteref" class="footnote">273</a>]</sup></p><p>Simply put, we need to use words effectively in organizing systems. To do that, we
            need to be careful about how we talk about the relationships among words and how words
            relate to concepts. There are two different contexts for those relationships. First, we
            need to discuss relationships among the meanings of words. Second, we need to discuss
            relationships among the form of words.</p><div class="sect2" title="Relationships among Word Meanings"><div class="titlepage"><div><div><h3 class="title" id="section-5.4.1">Relationships among Word Meanings</h3></div></div></div><p>There are several different types of relationships of word meanings. Not
                surprisingly, in most cases they parallel the types of relationships among concepts
                that we described in <a class="xref" href="ch05.html#section-5.3" title="The Semantic Perspective">The Semantic Perspective</a>.</p><div class="sect3" title="Hyponymy and Hyperonymy"><div class="titlepage"><div><div><h4 class="title" id="section-5.4.1.1">Hyponymy and Hyperonymy</h4></div></div></div><p><a id="id626841" class="indexterm"/><a id="id626850" class="indexterm"/><a id="id626866" class="indexterm"/><a id="id626876" class="indexterm"/><span><a id="def_hyponym"/>When words encode the semantic distinctions
                        expressed by class inclusion, the word for the more specific class in this
                        relationship is called the <a class="glossterm" href="go01.html#gloss_hyponym"><em class="glossterm">hyponym</em></a>, while the word for the more
                        general class to which it belongs is called the <em class="glossterm">hypernym</em>.</span> George Miller suggested an
                    exemplary formula for defining a hyponym as its hypernym preceded by
                    adjectives or followed by relative clauses that distinguish it from its
                        <em class="glossterm">co-hyponyms</em>, mutually exclusive
                    subtypes of the same hypernym. </p><div class="informalexample"><div class="literallayout"><p>    <span class="strong"><strong>hyponym = {adjective+} hypernym {distinguishing clause+}</strong></span></p></div></div><p>For example, robin is a hyponym of bird, and could be defined as <span class="quote">“<span class="quote">a
                        migratory bird that has a clear melodious song and a reddish breast with
                        gray or black upper plumage.</span>”</span> This definition does not describe every
                    property of robins, but it is sufficient to differentiate robins from bluebirds
                    or eagles.<sup>[<a id="chapter-5-endnote-22" href="#ftn.chapter-5-endnote-22" epub:type="noteref" class="footnote">274</a>]</sup></p></div><div class="sect3" title="Metonymy"><div class="titlepage"><div><div><h4 class="title" id="section-5.4.1.2">Metonymy</h4></div></div></div><p><a id="id626989" class="indexterm"/><a id="id627002" class="indexterm"/><span><a id="def_metonymy"/>Part-whole or meronymic semantic
                        relationships have lexical analogues in <em class="glossterm">metonomy</em>, when an entity is described by something that is
                        contained in or otherwise part of it.</span> A country’s capital city or a
                    building where its top leaders reside is often used as a metonym for the entire
                    government: <span class="quote">“<span class="quote">The White House announced today...</span>”</span> Similarly,
                    important concentrations of business activity are often metonyms for their
                    entire industries: <span class="quote">“<span class="quote">Wall Street was bailed out again...</span>”</span></p></div><div class="sect3" title="Synonymy"><div class="titlepage"><div><div><h4 class="title" id="section-5.4.1.3">Synonymy</h4></div></div></div><p><a class="glossterm" href="go01.html#gloss_synonymy"><em class="glossterm">Synonymy</em></a> is the relationship
                    between words that express the same semantic concept.<a id="id627088" class="indexterm"/><a id="id627073" class="indexterm"/><a id="id627084" class="indexterm"/><a id="id627102" class="indexterm"/><span><a id="def_absolute_synonyms"/>The strictest definition is that
                            <em class="glossterm">synonyms</em>
                        <span class="quote">“<span class="quote">are words that can replace each other in some class of contexts with
                            insignificant changes of the whole text’s
                        meaning.</span>”</span></span><sup>[<a id="chapter-5-endnote-23" href="#ftn.chapter-5-endnote-23" epub:type="noteref" class="footnote">275</a>]</sup> This is an extremely hard test to pass, except for acronyms or
                    compound terms like <span class="quote">“<span class="quote">USA,</span>”</span>
                    <span class="quote">“<span class="quote">United States,</span>”</span> and <span class="quote">“<span class="quote">United States of America</span>”</span> that
                    are completely substitutable.</p><p>Most synonyms are not <a class="glossterm" href="go01.html#gloss_absolute_synonyms"><em class="glossterm">absolute
                        synonyms</em></a> like the aforementioned, and instead are considered
                        <a class="glossterm" href="go01.html#gloss_propositional_synonyms"><em class="glossterm">propositional
                        synonyms</em></a>. <span><a id="def_propositional_synonyms"/><a class="glossterm" href="go01.html#gloss_propositional_synonyms"><em class="glossterm">Propositional
                            synonyms</em></a> are not identical in meaning, they are equivalent
                        enough in most contexts in that <a id="id627213" class="indexterm"/> substituting one for the other will not change the truth value
                        of the sentence that uses them.</span> This weaker test lets us treat word
                    pairs as synonyms even though their meanings differ in subtle ways. For example,
                    if we know that <span class="personname"><span class="firstname">Lisa</span> <span class="surname">Simpson</span></span> plays the violin, because <span class="quote">“<span class="quote">violin</span>”</span> and
                        <span class="quote">“<span class="quote">fiddle</span>”</span> are propositional synonyms, no one would disagree with
                    an assertion that Lisa Simpson can play the fiddle.</p><p>
                    <a id="id627240" class="indexterm"/>
                    <a id="id627252" class="indexterm"/>An unordered set of synonyms is often called a <a class="glossterm" href="go01.html#gloss_synset"><em class="glossterm">synset</em></a>, a term first
                    used by the <a id="id627275" class="indexterm"/><span class="orgname">WordNet</span>
                    <span class="quote">“<span class="quote">semantic dictionary</span>”</span> project started in 1985 by <span class="personname"><span class="firstname">George</span> <span class="surname">Miller</span></span> and others at <span class="orgname">Princeton’s Cognitive Science
                        program</span>.<sup>[<a id="chapter-5-endnote-24" href="#ftn.chapter-5-endnote-24" class="footnote">276</a>]</sup> Instead of using spelling as the primary organizing principle for
                    words, WordNet uses their semantic properties and relationships to create a
                    network that captures the idea that words and concepts are an inseparable
                    system. Synsets are interconnected by both semantic relationships and lexical
                    ones, enabling navigation in either space.<sup>[<a id="chapter-5-endnote-25" href="#ftn.chapter-5-endnote-25" class="footnote">277</a>]</sup></p></div><div class="sect3" title="Polysemy"><div class="titlepage"><div><div><h4 class="title" id="section-5.4.1.4">Polysemy</h4></div></div></div><p>We introduced the lexical relationship of <a class="glossterm" href="go01.html#gloss_polysemy"><em class="glossterm">polysemy</em></a>, when a word has several different
                    meanings or senses, in the context of problems with names (<a class="xref" href="ch03.html#section-3.4.2.2" title="Homonymy, Polysemy, and False Cognates">Homonymy, Polysemy, and False Cognates</a>). For example, the word <span class="quote">“<span class="quote">bank</span>”</span> can
                    refer to any number of objects and activities: river bank, money bank, bank
                    shots in basketball and billiards, an aircraft maneuver, to name a few.<sup>[<a id="chapter-5-endnote-26" href="#ftn.chapter-5-endnote-26" epub:type="noteref" class="footnote">278</a>]</sup></p><p>Polysemy is represented in <a id="id627437" class="indexterm"/><span class="application">WordNet</span> by including a word in multiple
                    synsets. This enables <span class="application">WordNet</span> to be an extremely
                    useful resource for sense disambiguation in natural language processing research
                    and applications. When a polysemous word is encountered, it and the words that
                    are nearby in the text are looked up in <span class="application">WordNet</span>. By
                    following the lexical relationships in the synset hierarchy, a <span class="quote">“<span class="quote">synset
                        distance</span>”</span> can be calculated. The smallest semantic distance between
                    the words, which identifies their most semantically specific hypernym, can be
                    used to identify the correct sense.<sup>[<a id="chapter-5-endnote-27" href="#ftn.chapter-5-endnote-27" epub:type="noteref" class="footnote">279</a>]</sup></p></div><div class="sect3" title="Antonymy"><div class="titlepage"><div><div><h4 class="title" id="section-5.4.1.5">Antonymy</h4></div></div></div><p><a id="id627554" class="indexterm"/><a id="id627563" class="indexterm"/><a id="id627574" class="indexterm"/><span><a id="def_antonymy"/><a class="glossterm" href="go01.html#gloss_antonymy"><em class="glossterm">Antonymy</em></a> is the lexical relationship between two words that
                        have opposite meanings. Antonymy is a very salient lexical relationship, and
                        for adjectives it is even more powerful than synonymy. </span>In word
                    association tests, when the probe word is a familiar adjective, the most common
                    response is its antonym; a probe of <span class="quote">“<span class="quote">good</span>”</span> elicits
                        <span class="quote">“<span class="quote">bad,</span>”</span> and vice versa. Like synonymy, antonomy is sometimes
                    exact and sometimes more graded.<sup>[<a id="chapter-5-endnote-28" href="#ftn.chapter-5-endnote-28" epub:type="noteref" class="footnote">280</a>]</sup></p><p><span><a id="def_binary_antonyms"/>Contrasting or <span class="bold"><strong><a class="glossterm" href="go01.html#gloss_binary_antonyms"><em class="glossterm">binary
                                antonyms</em></a></strong></span> are used in mutually exclusive
                        contexts where one or the other word can be used, but never both. For
                        example, <span class="quote">“<span class="quote">alive</span>”</span> and <span class="quote">“<span class="quote">dead</span>”</span> can never be used at
                        the same time to describe the state of some entity, because the meaning of
                        one excludes or contradicts the meaning of the other.</span></p><p>Other antonymic relationships between word pairs are less semantically sharp
                    because they can sometimes appear in the same context as a result of the broader
                    semantic scope of one of the words. <span class="quote">“<span class="quote">Large</span>”</span> and
                        <span class="quote">“<span class="quote">small,</span>”</span> or <span class="quote">“<span class="quote">old</span>”</span> and <span class="quote">“<span class="quote">young</span>”</span>
                    generally suggest particular regions on size or age continua, but <span class="quote">“<span class="quote">how
                        large is it?</span>”</span> or <span class="quote">“<span class="quote">how old is it?</span>”</span> can be asked about
                    resources that are objectively small or young.<sup>[<a id="chapter-5-endnote-29" href="#ftn.chapter-5-endnote-29" epub:type="noteref" class="footnote">281</a>]</sup></p></div></div><div class="sect2" title="Thesauri"><div class="titlepage"><div><div><h3 class="title" id="section-5.4.2">Thesauri</h3></div></div></div><p><span>The words that people naturally use when they describe resources reflect
                    their unique experiences and perspectives, and this means that people often use
                    different words for the same resource and the same words for different
                    ones.</span> Guiding people when they select description words from a
                    <a class="glossterm" href="go01.html#gloss_controlled_vocabulary"><em class="glossterm">controlled
                    vocabulary</em></a> is a partial solution to this <a class="glossterm" href="go01.html#gloss_vocabulary_problem"><em class="glossterm">vocabulary problem</em></a> (<a class="xref" href="ch03.html#section-3.4.2.1" title="The Vocabulary Problem">The Vocabulary Problem</a>) that becomes increasingly essential as the scope
                and scale of the organizing system grows. <span>A <span class="bold"><strong><a class="glossterm" href="go01.html#gloss_thesaurus"><em class="glossterm">thesaurus</em></a></strong></span> is a reference work that organizes words
                    according to their semantic and lexical relationships.</span>
                <span>Thesauri are often used by professionals when they describe
                    resources.</span></p><p><a id="id627825" class="indexterm"/><a class="glossterm" href="go01.html#gloss_thesaurus"><em class="glossterm">Thesauri</em></a> have been created for many domains and subject areas. Some
                thesauri are very broad and contain words from many disciplines, like the <span><a id="ref_LOC-SH"/><span class="citerefentry"><span class="refentrytitle">Library of Congress Subject Headings</span>(LOC-SH)</span></span> used to classify any published content. Other commonly
                used thesauri are more focused, like the <a id="id627845" class="indexterm"/><a id="id627853" class="indexterm"/><a id="id627860" class="indexterm"/>
                <em class="firstterm"><a id="first_AAT"/><span class="citerefentry"><span class="refentrytitle">Art and Architecture Thesaurus</span>(AAT)</span></em> developed by the <span class="orgname">Getty Trust</span> and
                the <span class="citerefentry"><span class="refentrytitle">Legislative Indexing Vocabulary</span></span> developed by the <span class="orgname">Library of Congress</span>.<sup>[<a id="chapter-5-endnote-30" href="#ftn.chapter-5-endnote-30" class="footnote">282</a>]</sup></p><p><a id="id627923" class="indexterm"/>
                <a id="id627951" class="indexterm"/>We can return to our simple food taxonomy to illustrate how a thesaurus
                annotates vocabulary terms with lexical and semantic relationships. The class
                inclusion relationships of <a class="glossterm" href="go01.html#gloss_hypernym"><em class="glossterm">hypernomy</em></a>
                and <a class="glossterm" href="go01.html#gloss_hyponym"><em class="glossterm">hyponymy</em></a> are usually encoded
                using <code class="literal">BT</code> (<span class="quote">“<span class="quote">broader term</span>”</span>) and <code class="literal">NT</code>
                    (<span class="quote">“<span class="quote">narrower term</span>”</span>):</p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Food BT Meat<br/>
        Beef NT Meat</strong></span></p></div></div><p>The BT and NT relationships in a thesaurus create a hierarchical system of words,
                but a thesaurus is more than a lexical taxonomy for some domain because it also
                encodes additional lexical relationships for the most important words. Many thesauri
                emphasize the cluster of relationships for these key words and de-emphasize the
                overall lexical hierarchy.</p><p>Because the purpose of a thesaurus is to reduce synonymy, it distinguishes among
                synonyms or near-synonyms by indicating one of them as a preferred term using
                    <code class="literal">UF</code> (<span class="quote">“<span class="quote">used for</span>”</span>):</p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Food UF Sustenance, Nourishment</strong></span></p></div></div><p>A thesaurus might employ <code class="literal">USE</code> as the inverse of the
                    <code class="literal">UF</code> relationship to refer from a less preferred or variant
                term to a preferred one:</p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Victuals USE Food</strong></span></p></div></div><p>Thesauri also use <code class="literal">RT</code> (<span class="quote">“<span class="quote">related term</span>”</span> or <span class="quote">“<span class="quote">see
                    also</span>”</span>) to indicate terms that are not synonyms but which often occur in
                similar contexts:</p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>Food RT Cooking, Dining, Cuisine</strong></span></p></div></div></div><div class="sect2" title="Relationships among Word Forms"><div class="titlepage"><div><div><h3 class="title" id="section-5.4.3">Relationships among Word Forms</h3></div></div></div><p>The relationships among word meanings are critically important. Whenever we
                create, combine, or compare resource descriptions we also need to pay attention to
                relationships between word forms. These relationships begin with the idea that all
                natural languages create words and word forms from smaller units. <a id="id628122" class="indexterm"/><a id="id628131" class="indexterm"/><span><a id="def_morphology"/>The basic building blocks for words are
                    called <a class="glossterm" href="go01.html#gloss_morphemes"><em class="glossterm">morphemes</em></a> and can
                    express semantic concepts (when they are called <em class="glossterm">root
                        words</em> ) or abstract concepts like <span class="quote">“<span class="quote">pastness</span>”</span> or
                        <span class="quote">“<span class="quote">plural</span>”</span>). The analysis of the ways by which languages combine
                        <a class="glossterm" href="go01.html#gloss_morphemes"><em class="glossterm">morphemes</em></a> is called
                        <a class="glossterm" href="go01.html#gloss_morphology"><em class="glossterm">morphology</em></a>.</span><sup>[<a id="chapter-5-endnote-31" href="#ftn.chapter-5-endnote-31" epub:type="noteref" class="footnote">283</a>]</sup></p><p><span class="action">Morphological analysis</span> of a language is heavily used in text
                processing to create indexes for information retrieval; for example,
                        <span><a class="glossterm" href="go01.html#gloss_stemming"><em class="glossterm">stemming</em></a> (discussed in more detail in <a class="xref" href="ch09.html" title="Chapter 9. Interactions with Resources">Chapter 9</a>) is morphological processing which removes prefixes and
                    suffixes to leave the root form of words.</span> Similarly, simple text
                processing applications like hyphenation and spelling correction solve word form
                problems using roots and rules because it is more scalable and robust than solving
                them using word lists. Many misspellings of common words (e.g., <span class="quote">“<span class="quote">pain</span>”</span>)
                are words of lower frequency (e.g., <span class="quote">“<span class="quote">pane</span>”</span>), so adding
                    <span class="quote">“<span class="quote">pane</span>”</span> to a list of misspelled words would occasionally identify it
                incorrectly. In addition, because natural languages are generative and create new
                words all the time, a word list can never be complete; for example, when
                    <span class="quote">“<span class="quote">flickr</span>”</span> occurs in text, is it a misspelling of
                    <span class="quote">“<span class="quote">flicker</span>”</span> or the correct spelling of the popular photo-sharing
                site?</p><div class="sect3" title="Derivational Morphology"><div class="titlepage"><div><div><h4 class="title" id="section-5.4.3.1">Derivational Morphology</h4></div></div></div><p><a id="id628292" class="indexterm"/><a id="id628316" class="indexterm"/><span><a id="def_derivational_morphology"/><a class="glossterm" href="go01.html#gloss_derivational_morphology"><em class="glossterm">Derivational
                            morphology</em></a> deals with how words are created by combining
                        morphemes.</span>
                    <a class="glossterm" href="go01.html#gloss_compounding"><em class="glossterm">Compounding</em></a>, putting two <span class="quote">“<span class="quote">free morphemes</span>”</span> together
                    as in <span class="quote">“<span class="quote">batman</span>”</span> or <span class="quote">“<span class="quote">catwoman,</span>”</span> is an extremely powerful
                    mechanism. The meaning of some compounds is easy to understand when the first
                    morpheme qualifies or restricts the meaning of the second, as in
                        <span class="quote">“<span class="quote">birdcage</span>”</span> and <span class="quote">“<span class="quote">tollbooth.</span>”</span><sup>[<a id="chapter-5-endnote-32" href="#ftn.chapter-5-endnote-32" epub:type="noteref" class="footnote">284</a>]</sup> However, many compounds take on new meanings that are not as
                    literally derived from the meaning of their constituents, like
                        <span class="quote">“<span class="quote">seahorse</span>”</span> and <span class="quote">“<span class="quote">batman.</span>”</span></p><p>Other types of derivations using <span class="quote">“<span class="quote">bound</span>”</span> morphemes follow more
                    precise rules for combining them with <span class="quote">“<span class="quote">base</span>”</span> morphemes. The most
                    common types of bound morphemes are prefixes and suffixes, which usually create
                    a word of a different part-of-speech category when they are added. Familiar
                    English prefixes include <span class="quote">“<span class="quote">a-,</span>”</span>
                    <span class="quote">“<span class="quote">ab-,</span>”</span>
                    <span class="quote">“<span class="quote">anti-,</span>”</span>
                    <span class="quote">“<span class="quote">co-,</span>”</span>
                    <span class="quote">“<span class="quote">de-,</span>”</span>
                    <span class="quote">“<span class="quote">pre-,</span>”</span> and <span class="quote">“<span class="quote">un-.</span>”</span> Among the most common English
                    suffixes are <span class="quote">“<span class="quote">-able,</span>”</span>
                    <span class="quote">“<span class="quote">-ation,</span>”</span>
                    <span class="quote">“<span class="quote">-ify,</span>”</span>
                    <span class="quote">“<span class="quote">ing,</span>”</span>
                    <span class="quote">“<span class="quote">-ity,</span>”</span>
                    <span class="quote">“<span class="quote">-ize,</span>”</span>
                    <span class="quote">“<span class="quote">-ment,</span>”</span> and <span class="quote">“<span class="quote">-ness.</span>”</span> Compounding and adding prefixes
                    or suffixes are simple mechanisms, but very complex words like
                        <span class="quote">“<span class="quote">unimaginability</span>”</span> can be formed by using them in
                    combination.</p></div><div class="sect3" title="Inflectional Morphology"><div class="titlepage"><div><div><h4 class="title" id="section-5.4.2.2">Inflectional Morphology</h4></div></div></div><p><a id="id628570" class="indexterm"/><a id="id628582" class="indexterm"/><span><a id="def_inflectional_morphology"/>Inflectional mechanisms
                        change the form of a word to represent tense, aspect, agreement, or other
                        grammatical information. Unlike derivation, inflection never changes the
                        part-of-speech of the base morpheme. The <span class="strong"><strong><em class="glossterm"><a id="term_inflectional_morphology"/>inflectional
                                morphology</em></strong></span> of English is relatively simple
                        compared with other languages.</span><sup>[<a id="chapter-5-endnote-33" href="#ftn.chapter-5-endnote-33" class="footnote">285</a>]</sup></p></div></div></div><div class="sect1" title="The Structural Perspective"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="section-5.5">The Structural Perspective</h2></div></div></div><p>The <a class="glossterm" href="go01.html#gloss_structural_perspective"><em class="glossterm">structural perspective</em></a> analyzes the
            association, arrangement, proximity, or connection between resources without primary
            concern for their meaning or the origin of these relationships.<sup>[<a id="chapter-5-endnote-34" href="#ftn.chapter-5-endnote-34" epub:type="noteref" class="footnote">286</a>]</sup> We take a structural perspective when we define a family as <span class="quote">“<span class="quote">a
                collection of people</span>”</span> or when we say that a particular family like the
            Simpsons has five members. Sometimes all we know is that two resources are connected, as
            when we see a highlighted word or phrase that is pointing from the current web page to
            another. At other times we might know more about the reasons for the relationships
            within a set of resources, but we still focus on their structure, essentially merging or
            blurring all of the reasons for the associations into a single generic notion that the
            resources are connected. We do this when we analyze communication or interaction
            patterns to determine the number of <span class="quote">“<span class="quote">degrees of separation</span>”</span> between any
            pair of resources.<sup>[<a id="chapter-5-endnote-35" href="#ftn.chapter-5-endnote-35" class="footnote">287</a>]</sup></p><p>Many types of resources have internal structure in addition to their structural
            relationships with other resources. Of course, we have to remember (as we discussed in
                <a class="xref" href="ch03.html#section-3.3" title="Resource Identity">Resource Identity</a>) that we often face arbitrary choices about the
            abstraction and granularity with which we describe the parts that make up a resource and
            whether some combination of resource should also be identified as a resource. This is
            not easy when you are analyzing the structure of a car with its thousands of parts, and
            it is ever harder with information resources where there are many more ways to define
            parts and wholes. However, an advantage for information resources is that their internal
            structural descriptions are usually highly <span class="quote">“<span class="quote">computable,</span>”</span> something we
            consider in depth in <a class="xref" href="ch09.html" title="Chapter 9. Interactions with Resources">Chapter 9</a>.</p><div class="sect2" title="Intentional, Implicit, and Explicit Structure"><div class="titlepage"><div><div><h3 class="title" id="section-5.5.1">Intentional, Implicit, and Explicit Structure</h3></div></div></div><p>In the discipline of organizing we emphasize <span class="quote">“<span class="quote">intentional structure</span>”</span>
                created by people or by computational processes rather than accidental or
                naturally-occurring structures created by physical, geological, biological or
                genetic processes. We acknowledged in <a class="xref" href="ch01.html#section-1.2.3" title="The Concept of “Intentional Arrangement”">The Concept of <span class="quote">“<span class="quote">Intentional Arrangement</span>”</span></a> that there is
                information in the piles of debris left after a tornado or tsunami and in the strata
                of the Grand Canyon. Similarly, we can perceive a pattern of stars and name it Orion
                or the Big Dipper, but this structural organization only exists from our galactic
                point of view; the stars that make up these constellations are at significantly
                different distances from Earth. These structural patterns might be of interest to
                meteorologists, geologists, astronomers or others but because they were not created
                by an identifiable agent following one or more organizing principles, they are not
                our primary focus.</p><p>Some organizing principles impose very little structure. For a small collection of
                resources, co-locating them or arranging them near each other might be sufficient
                organization. We can impose two- or three-dimensional coordinate systems on this
                    <span class="quote">“<span class="quote">implicit structure</span>”</span> and explicitly describe the location of a
                resource as precisely as we want, but we more naturally describe the structure of
                resource locations in relative terms. In English we have many ways to describe the
                structural relationship of one resource to another: <span class="quote">“<span class="quote">in,</span>”</span>
                <span class="quote">“<span class="quote">on,</span>”</span>
                <span class="quote">“<span class="quote">under,</span>”</span>
                <span class="quote">“<span class="quote">behind,</span>”</span>
                <span class="quote">“<span class="quote">above,</span>”</span>
                <span class="quote">“<span class="quote">below,</span>”</span>
                <span class="quote">“<span class="quote">near,</span>”</span>
                <span class="quote">“<span class="quote">to the right of,</span>”</span>
                <span class="quote">“<span class="quote">to the left of,</span>”</span>
                <span class="quote">“<span class="quote">next to,</span>”</span> and so on. Sometimes several resources are arranged or
                appear to be arranged in a sequence or order and we can use positional descriptions
                of structure: a late 1990s TV show described the planet Earth as <span class="quote">“<span class="quote">the third
                    rock from the Sun.</span>”</span><sup>[<a id="chapter-5-endnote-36" href="#ftn.chapter-5-endnote-36" class="footnote">288</a>]</sup></p><p>We pay most attention to intentional structures that are explicitly represented
                within and between resources because they embody the design or authoring choices
                about how much implicit or latent structure will be made explicit. Structures that
                can be reliably extracted by algorithms become especially important for very large
                collections of resources whose scope and scale defy structural analysis by
                people.</p></div><div class="sect2" title="Structural Relationships within a Resource"><div class="titlepage"><div><div><h3 class="title" id="section-5.5.2">Structural Relationships within a Resource</h3></div></div></div><p>We almost always think of human and other animate resources as unitary entities.
                Likewise, many physical resources like paintings, sculptures, and manufactured goods
                have a material integrity that makes us usually consider them as indivisible. For an
                information resource, however, it is almost always the case that it has or might
                have had some internal structure or sub-division of its constituent data
                elements.</p><p>In fact, since all computer files are merely encodings of bits, bytes, characters
                and strings, we can say with some certainty that most digital resources exhibit some
                internal structure, even if that structure is only discernible by software agents.
                The internal formats of word processing files, for example, have changed many times
                since their invention in the mid-twentieth century, converging on
                    <abbr class="abbrev">XML</abbr> in the early twenty-first century.</p><p>When an author writes a document, he or she gives it some internal organization
                with its title, section headings, typographic conventions, page numbers, and other
                mechanisms that identify its parts and their significance or relationship to each
                other. The lowest level of this structural hierarchy, usually the paragraph,
                contains the text content of the document. Sometimes the author finds it useful to
                identify types of content like glossary terms or cross-references within the
                paragraph text. Document models like these that mix structural description with
                content <span class="quote">“<span class="quote">nuggets</span>”</span> in the text are said to contain <span class="bold"><strong>mixed
                    content</strong></span> (See the Sidebar.)</p><p>In data-intensive or transactional domains, document instances tend to be
                homogeneous because they are produced by or for automated processes, and their
                information components will appear predictably in the same structural relationships
                with each other. These structures typically form a hierarchy expressed in an
                <abbr class="abbrev">XML</abbr> schema or word processing style template.
                <abbr class="abbrev">XML</abbr> documents describe their component parts using
                content-oriented elements like <code class="sgmltag-starttag">&lt;ITEM&gt;</code>, <code class="sgmltag-starttag">&lt;NAME&gt;</code>, and <code class="sgmltag-starttag">&lt;ADDRESS&gt;</code>, that are themselves often aggregate structures or containers for
                more granular elements. The structures of resources maintained in databases are
                typically less hierarchical, but the structures are precisely captured in database
                schemas.</p><p><a id="id629105" class="indexterm"/></p><div class="sidebar"><a id="chapter-5-sidebar-MixedContent"/><div class="sidebar-title">Mixed Content</div><p><span><a id="def_mixed_content"/><span class="bold"><strong><em class="glossterm"><a id="term_mixed_content"/>Mixed content</em></strong></span>
                        distinguishes <abbr class="abbrev">XML</abbr> from other data representation languages.
                        It is this structural feature, combined with the fact that child nodes in
                        the <abbr class="abbrev">XML</abbr> Infoset (<a class="xref" href="ch08.html#section-8.2.2.2" title="XML Information Set">XML Information Set</a>) are ordered, that makes it possible for
                            <abbr class="abbrev">XML</abbr> documents to function both as human
                        reader-oriented, textual documents and as structured data formats. It allows
                        us to use natural language in writing descriptions while still enabling us
                        to identify content by type by embedding markup to enclose <span class="quote">“<span class="quote">semantic
                            nuggets</span>”</span> in otherwise undifferentiated text.</span><sup>[<a id="chapter-8-endnote-13" href="#ftn.chapter-8-endnote-13" epub:type="noteref" class="footnote">289</a>]</sup></p><p><a id="id629248" class="indexterm"/><a id="id629274" class="indexterm"/> The <em class="citetitle">Guidelines for Electronic Text Encoding and
                        Interchange</em>, produced by the <span class="citerefentry"><span class="refentrytitle"><span class="orgname">Text Encoding Initiative</span></span>(TEI)</span>, for example, includes a set of elements and attributes for
                        <em class="citetitle">Names, Dates, People and Places</em>.<sup>[<a id="id629289" href="#ftn.id629289" class="footnote">290</a>]</sup></p></div><p><a id="id629308" class="indexterm"/><a id="id629313" class="indexterm"/>The internal parts of <abbr class="abbrev">XML</abbr> documents can be described,
                found and selected using the XPath language, which defines the structures and
                patterns used by <abbr class="abbrev">XML</abbr> forms, queries, and transformations. The key
                idea used by XPath is that the structure of <abbr class="abbrev">XML</abbr> documents is a tree
                of information items called nodes, whose locations are described in terms of the
                relationships between nodes. The relationships built into XPath, which it calls
                axes, include self, child, parent, following, and preceding, making it very easy to
                specify a structure-based query like <span class="quote">“<span class="quote">find all sections in Chapter 1 through
                    Chapter 5 that have at least two levels of subsections.</span>”</span><sup>[<a id="chapter-5-endnote-37" href="#ftn.chapter-5-endnote-37" epub:type="noteref" class="footnote">291</a>]</sup> In addition, tools like Schematron take advantage of XPath’s structural
                descriptions to test assertions about a document’s structure and content. For
                example, a common editorial constraint might be that a numbered list must have at
                least three items.<sup>[<a id="chapter-5-endnote-38" href="#ftn.chapter-5-endnote-38" epub:type="noteref" class="footnote">292</a>]</sup></p><p><a id="id629380" class="indexterm"/>In more qualitative, less information-intensive and more
                experience-intensive domains, we move toward the narrative end of the Document Type
                Spectrum, and document instances become more heterogeneous because they are produced
                by and for people (See the Sidebar, <a class="xref" href="ch03.html#chapter-3-sidebar-1" title="The Document Type Spectrum">The Document Type Spectrum</a> in <a class="xref" href="ch03.html#section-3.2.1" title="Resource Domain">Resource Domain</a>). The information conveyed in the
                documents is conceptual or thematic rather than transactional, and the structural
                relationships between document parts are much weaker. Instead of precise structure
                and content rules,, there is usually just a shallow hierarchy marked up with Word
                processing or <abbr class="abbrev">HTML</abbr> tags like <code class="sgmltag-starttag">&lt;HEAD&gt;</code>, <code class="sgmltag-starttag">&lt;H1&gt;</code>, <code class="sgmltag-starttag">&lt;H2&gt;</code>, and <code class="sgmltag-starttag">&lt;LIST&gt;</code>.</p><p><a id="id629425" class="indexterm"/></p><div class="sidebar"><div class="sidebar-title">Structural Metadata</div><p>Structural metadata, in the form of a schema for a database or document,
                    describes a class of information resource, and may also prescribe grammatical
                    details of inclusion and attribution relationships among the components. For
                    example, the chapters of this book contain four levels of subsections. Each of
                    those sections contains a title, some paragraphs and other text blocks, and
                    subordinate sections. The textual content of the paragraphs includes highlighted
                    terms and phrases that are defined <span xml:lang="latin" class="foreignphrase"><em xml:lang="latin" class="foreignphrase">in
                        situ</em></span> and referenced again in the glossary and index; there
                    are also bibliographic citations that are reflected in the bibliography and
                    index. We can discover these characteristics of a book through observation, but
                    we could also examine its structural metadata, in its schema.</p><p><a id="id629446" class="indexterm"/>The schema most commonly used for producing technical books is
                    called DocBook; it describes every XML element and attribute and prescribes
                    their grammatical forms. The schema lets us know that a formal paragraph must
                    include a title, and that a title may contain emphasis. A schema can also
                    describe and prescribe the lexical value space of a postal code, or require that
                    every list must have at least three items. The DocBook schema is well-documented
                    and has been production-tested in institutional publishing contexts for over
                    twenty years.<sup>[<a id="chapter-5-endnote-36a" href="#ftn.chapter-5-endnote-36a" epub:type="noteref" class="footnote">293</a>]</sup></p><p>Structural metadata allows us to describe and prescribe relations among
                    database tables, within the chapters of a book, or among parts in an inventory
                    management system. The schema for HTML, for example, informs us that the
                        <code class="sgmltag-starttag">&lt;A&gt;</code> element can be used to signal a
                    hypertext link-end; whether that link-end is an anchor or a target, or both,
                    depends on the combination of values assigned to attributes. In HTML, the
                    optional <code class="sgmltag-attribute">REL</code> attribute may
                    contain a value that signals purpose of a hypertext link, and any HTML element
                    may include a <code class="sgmltag-attribute">CLASS</code> attribute value that
                    may be used as a CSS selector for the purposes of formatting.</p><p><a id="id629481" class="indexterm"/>The usefulness of any given schema is often a function of precision
                    with which we may make useful statements based upon the descriptions and
                    prescriptions it offers. Institutional schemas tend to be more prescriptive and
                    restrictive, stressing professional orthodoxy and conformance to controlled
                    vocabularies. Schemas for the information content in social and informal
                    applications tend to be less prescriptive. Whether and how we use structural
                    metadata is a tradeoff. Structural metadata is essential to enable quality
                    control and maintenance in information collection and publishing processes, but
                    someone has to do the work to create it.</p></div><p>The internal structural hierarchy in a resource is often extracted and made into a
                separate and familiar description resource called the <span class="quote">“<span class="quote">table of
                    contents</span>”</span> to support finding and navigation interactions with the primary
                resource. In a printed media context, any given content resource is likely to only
                be presented once, and its page number is provided in the table of contents to allow
                the reader to locate the chapter, section or appendix in question. In a hypertext
                media context, a given resource may be a chapter in one book while being an appendix
                in another. Some tables of contents are created as a static structural description,
                but others are dynamically generated from the internal structures whenever the
                resource is accessed. In addition, other types of entry points can be generated from
                the names or descriptions of content components, like selectable lists of tables,
                figures, maps, or code examples.</p><p>Identifying the components and their structural relationships in documents is
                easier when they follow consistent rules for structure (e.g., every non-text
                component must have a title and caption) and presentation (e.g., <a class="glossterm" href="go01.html#gloss_hypertext_link"><em class="glossterm">hypertext links</em></a> in web pages are
                underlined and change cursor shapes when they are <span class="quote">“<span class="quote">moused over</span>”</span>) that
                reinforce the distinctions between types of information components. Structural and
                presentation features are often ordered on some dimension (e.g., type size, line
                width, amount of white space) and used in a correlated manner to indicate the
                importance of a content component.<sup>[<a id="chapter-5-endnote-39" href="#ftn.chapter-5-endnote-39" epub:type="noteref" class="footnote">294</a>]</sup></p><p>Many indexing algorithms treat documents as <span class="quote">“<span class="quote">bags of words</span>”</span> to
                compute statistics about the frequency and distribution of the words they contain
                while ignoring all semantics and structure. In <a class="xref" href="ch09.html" title="Chapter 9. Interactions with Resources">Chapter 9</a>, we contrast this approach with algorithms that use internal
                structural descriptions to retrieve more specific parts of documents.</p></div><div class="sect2" title="Structural Relationships between Resources"><div class="titlepage"><div><div><h3 class="title" id="section-5.5.3">Structural Relationships between Resources</h3></div></div></div><p>Many types of resources have <span class="quote">“<span class="quote">structural relationships</span>”</span> that
                interconnect them. Web pages are almost always linked to other pages. Sometimes the
                links among a set of pages remain mostly within those pages, as they are in an
                e-commerce catalog site. More often, however, links connect to pages in other sites,
                creating a link network that cuts across and obscures the boundaries between
                sites.</p><p>The links between documents can be analyzed to infer connections between the
                authors of the documents. Using the pattern of links between documents to understand
                the structure of knowledge and of the intellectual community that creates it is not
                a new idea, but it has been energized as more of the information we exchange with
                other people is on the web or otherwise in digital formats. An important function in
                    <span class="application">Google’s search engine</span> is the <span class="strong"><strong>page rank</strong></span> algorithm that calculates the relevance of a page in part
                using the number of links that point to it while giving greater weight to pages that
                are themselves linked to often.<sup>[<a id="chapter-5-endnote-40" href="#ftn.chapter-5-endnote-40" class="footnote">295</a>]</sup></p><p>Web-based social networks enable people to express their connections with other
                people directly, bypassing the need to infer the connections from links in documents
                or other communications.</p><div class="sect3" title="Hypertext Links"><div class="titlepage"><div><div><h4 class="title" id="section-5.5.3.1">Hypertext Links</h4></div></div></div><p><span><a id="def_hypertext_link"/>The concept of read-only or follow-only
                        structures that connect one document to another is usually attributed to <span class="personname"><span class="firstname">Vannevar</span> <span class="surname">Bush</span></span> in his seminal 1945 essay titled <a class="link" href="bi01.html#Bush1945" title="“As We May Think”">“<span class="citetitle">As We May
                            Think.</span>”</a> Bush called it <span class="quote">“<span class="quote">associative indexing,</span>”</span>
                        defined as <span class="quote">“<span class="quote">a provision whereby any item may be caused at will to
                            select immediately and automatically another.</span>”</span></span><sup>[<a id="chapter-5-endnote-41" href="#ftn.chapter-5-endnote-41" class="footnote">296</a>]</sup> The <span class="quote">“<span class="quote">item</span>”</span> connected in this way was for Bush most
                    often a book or a scientific article. However, the anchor and destination of a
                    hypertext link can be a resource of any granularity, ranging from a single point
                    or character, a paragraph, a document, or any part of the resource to which the
                    ends of link are connected. The anchor and destination of a web link are its
                    structural specification, but we often need to consider links from other
                    perspectives. (See the Sidebar, <a class="xref" href="ch05.html#chapter-5-sidebar-1" title="Perspectives on Hypertext Links">Perspectives on Hypertext Links</a>).</p><p><a id="id629952" class="indexterm"/><span class="personname"><span class="firstname">Theodor</span> <span class="othername">Holm</span> <span class="surname">Nelson</span></span>, in a book intriguingly titled <a class="link" href="bi01.html#Nelson1981" title="Literary Machines: The Report On, and Of, Project Xanadu Concerning Word Processing, Electronic Publishing, Hypertext, Thinkertoys, Tomorrow’s Intellectual Revolution, and Certain Other Topics Including Knowledge, Education and Freedom"><em class="citetitle">Literary
                        Machines</em></a>, renamed associative indexing as <span class="quote">“<span class="quote">hypertext</span>”</span> decades later, expanding the idea to make it a writing
                    style as well as a reading style.<sup>[<a id="chapter-5-endnote-42" href="#ftn.chapter-5-endnote-42" epub:type="noteref" class="footnote">297</a>]</sup> Nelson urged writers to use hypertext to create non-sequential
                    narratives that gave choices to readers, using a novel technique for which he
                    coined the term <span class="quote">“<span class="quote">transclusion.</span>”</span>
                    <sup>[<a id="chapter-5-endnote-42a" href="#ftn.chapter-5-endnote-42a" epub:type="noteref" class="footnote">298</a>]</sup></p><p><a id="id630153" class="indexterm"/><a id="id630165" class="indexterm"/>At about the same time, and without knowing about Nelson’s work, <span class="personname"><span class="firstname">Douglas</span> <span class="surname">Engelbart</span></span>’s <em class="citetitle">Augmenting the Human Intellect</em>, described
                    a future world in which professionals equipped with interactive computer
                    displays utilize an information space consisting of a cross-linked
                        resources.<sup>[<a id="chapter-5-endnote-43" href="#ftn.chapter-5-endnote-43" epub:type="noteref" class="footnote">299</a>]</sup></p><p>In the 1960s, computers lacked graphic displays and were primarily employed to
                    solve complex mathematical and scientific problems that might take minutes,
                    hours or even days to complete, Nelson’s and Engelbart’s visions of
                    hypertext-based personal computing may have seemed far-fetched. In spite of
                    this, by 1968, Engelbart and his team demonstrated human computer interface
                    including the mouse, hypertext, and interactive media, along with a set of
                    guiding principles.<sup>[<a id="chapter-5-endnote-44" href="#ftn.chapter-5-endnote-44" class="footnote">300</a>]</sup></p><p><a id="id630345" class="indexterm"/><a id="id630348" class="indexterm"/><a id="id630286" class="indexterm"/> Hypertext links are now familiar structural mechanisms in
                    information applications because of the World Wide Web, proposed in 1989 by <span class="personname"><span class="firstname">Tim</span> <span class="surname">Berners-Lee</span></span> and <span class="personname"><span class="firstname">Robert</span> <span class="surname">Cailliau</span></span>.<sup>[<a id="chapter-5-endnote-44a" href="#ftn.chapter-5-endnote-44a" epub:type="noteref" class="footnote">301</a>]</sup> They invented the methods for encoding and following <a class="glossterm" href="go01.html#gloss_hypertext_link"><em class="glossterm">hypertext links</em></a> using the now
                    popular <span class="citerefentry"><span class="refentrytitle">HyperText Markup Language</span>(HTML)</span>.<sup>[<a id="chapter-5-endnote-45" href="#ftn.chapter-5-endnote-45" epub:type="noteref" class="footnote">302</a>]</sup> The resources connected by <abbr class="abbrev">HTML</abbr>’s hypertext links
                    are not limited to text or documents. Selecting a hypertext link can invoke a
                    connected resource that might be a picture, video, or interactive
                        application.<sup>[<a id="chapter-5-endnote-46" href="#ftn.chapter-5-endnote-46" epub:type="noteref" class="footnote">303</a>]</sup></p><p><a id="id630495" class="indexterm"/>By 1993, personal computers, with a graphic display, speakers
                    and a mouse pointer, had become ubiquitous. <span class="application"><abbr class="abbrev">NCSA</abbr>
                        Mosaic</span> is widely credited with popularizing the World Wide Web
                    and <abbr class="abbrev">HTML</abbr> in 1993, by introducing inline graphics, audio and
                    video media, rather than having to link to media segments in a separate window.<sup>[<a id="id630550" href="#ftn.id630550" class="footnote">304</a>]</sup> The team in <span class="personname"><span class="firstname">Joseph</span> <span class="surname">Hardin</span></span>’s lab at <abbr class="abbrev">NCSA</abbr> recognized that adding the ability
                    to transclude images and other media would transform the World Wide Web from a
                    text-only viewer with links to a new publishing paradigm, a <span class="quote">“<span class="quote">networked
                        landscape</span>”</span> with hypertext signposts to guide the way. On 12 November
                    1993, the first full release of <abbr class="abbrev">NCSA</abbr> Mosaic on the world’s
                    three most popular operating systems (X Windows, Microsoft Windows and Apple
                    Macintosh) enabled the general public to access the network with a graphical browser.<sup>[<a id="id630677" href="#ftn.id630677" epub:type="noteref" class="footnote">305</a>]</sup> Since browsers made them familiar, hypertext links have been used in
                    other computing applications as structure and navigation mechanisms.</p><div class="sidebar"><a id="chapter-5-sidebar-1"/><div class="sidebar-title">Perspectives on Hypertext Links</div><p>A lexical perspective on hypertext links concerns the words that are used
                        to signal the presence of a link or to encode its type. <a id="id630750" class="indexterm"/><a id="id630764" class="indexterm"/><span><a id="def_anchor_text"/>In web contexts, the words in which
                            a structural link is embedded are called the <a class="glossterm" href="go01.html#gloss_anchor_text"><em class="glossterm">anchor
                                text</em></a>.</span> More generally, rhetorical structure
                        theory analyzes how different conventions or signals in texts indicate
                        relationships between texts or parts of them, like the subtle differences in
                        polarity among <span class="quote">“<span class="quote">see,</span>”</span>
                        <span class="quote">“<span class="quote">see also,</span>”</span> and <span class="quote">“<span class="quote">but see</span>”</span> as citation
                            signals.<sup>[<a id="chapter-5-endnote-47" href="#ftn.chapter-5-endnote-47" epub:type="noteref" class="footnote">306</a>]</sup></p><p>Many hypertext links in web pages are purely structural because they lack
                        explicit representation of the reason for the relationship. <a id="id630861" class="indexterm"/><a id="id630854" class="indexterm"/><span><a id="def_link_type"/>When it is evident, this semantic
                            property of the link is called the <span class="strong"><strong><a class="glossterm" id="term_link_type" href="go01.html#gloss_link_type"><em class="glossterm">link
                            type</em></a>.</strong></span></span><sup>[<a id="chapter-5-endnote-48" href="#ftn.chapter-5-endnote-48" epub:type="noteref" class="footnote">307</a>]</sup></p><p>An architectural perspective on links considers whether links are
                            <a class="glossterm" href="go01.html#gloss_one-way"><em class="glossterm">one-way</em></a> or <a class="glossterm" href="go01.html#gloss_bi-directional"><em class="glossterm">bi-directional</em></a>. <span><a id="def_bi-directional_link"/>When a bi-directional link is created
                            between an anchor and a destination, it is as though a one-way link that
                            can be followed in the opposite direction is automatically created. Two
                            one-way links serve the same purpose, but the return link is not
                            automatically established when the first one is created.</span> A
                        second architectural consideration is whether links are <em class="glossterm">binary</em>, connecting one anchor to one
                        destination, or <span class="strong"><strong>n-ary</strong></span>, connecting one
                        anchor to multiple types of destinations.<sup>[<a id="chapter-5-endnote-49" href="#ftn.chapter-5-endnote-49" epub:type="noteref" class="footnote">308</a>]</sup> (See <a class="xref" href="ch05.html#section-5.6" title="The Architectural Perspective">The Architectural Perspective</a>).</p><p>A <span class="quote">“<span class="quote">front end</span>”</span> or <span class="quote">“<span class="quote">surface</span>”</span> implementation
                        perspective on hypertext links concerns how the presence of the link is
                        indicated in a user interface; this is called the <span class="quote">“<span class="quote">link marker</span>”</span>; underlining or coloring of
                        clickable text are conventional markers for web links.<sup>[<a id="chapter-5-endnote-50" href="#ftn.chapter-5-endnote-50" epub:type="noteref" class="footnote">309</a>]</sup> A <span class="quote">“<span class="quote">back end</span>”</span> implementation issue is whether links
                        are contained or embedded in the resources they link or whether they are
                        stored separately in a <span class="quote">“<span class="quote">link base.</span>”</span><sup>[<a id="chapter-5-endnote-51" href="#ftn.chapter-5-endnote-51" epub:type="noteref" class="footnote">310</a>]</sup> (See <a class="xref" href="ch05.html#section-5.7" title="The Implementation Perspective">The Implementation Perspective </a>).</p></div></div><div class="sect3" title="Analyzing Link Structures"><div class="titlepage"><div><div><h4 class="title" id="section-5.5.3.2">Analyzing Link Structures</h4></div></div></div><p>We can portray a set of links between resources graphically as a pattern of
                    boxes and links. Because a link connection from one resource to another need not
                    imply a link in the opposite direction, we distinguish one-way links from
                    explicitly bi-directional ones.</p><div class="figure"><a id="Chapter5-5-3-2"/><div class="figure-contents"><div class="mediaobject"><img src="figs/print/ch5.3-350dpi.png" alt="The structure of links between web resources can be represented graphically or in a matrix.  &#10;                            The matrix representation is a more abstract one that can be analyzed by computers."/></div></div><div class="figure-title">Figure 5-3. Representing Link Structures.</div></div><p>A graphical representation of link structure is shown on the left panel of
                    figure <a class="xref" href="ch05.html#Chapter5-5-3-2" title="Figure 5-3. Representing Link Structures.">Figure 5-3</a>. For a small network of links, a diagram like this one makes it easy to see
                    that some resources have more incoming or outgoing links than other resources.
                    However, for most purposes we leave the analysis of link structures to computer
                    programs, and there it is much better to represent the link structures more
                    abstractly in matrix form. In this matrix the resource identifiers on the row
                    and column heads represent the source and destination of the link. This is a
                    full matrix because not all of the links are symmetric; a link from resource 1
                    to resource 2 does not imply one from 2 to 1.</p><p>A matrix representation of the same link structure is shown on the right panel
                    of figure <a class="xref" href="ch05.html#Chapter5-5-3-2" title="Figure 5-3. Representing Link Structures.">Figure 5-3</a>. This representation models the network as a directed graph in which the
                    resources are the vertices and the relationships are the edges that connect
                    them. We now can apply graph algorithms to determine many useful properties. A
                    very important property is <a class="glossterm" href="go01.html#gloss_reachability"><em class="glossterm">reachability</em></a>, the <span class="quote">“<span class="quote">can you get
                        there from here</span>”</span> property.<sup>[<a id="chapter-5-endnote-52" href="#ftn.chapter-5-endnote-52" epub:type="noteref" class="footnote">311</a>]</sup> Other useful properties include the average number of incoming or
                    outgoing links, the average distance between any two resources, and the shortest
                    path between them.</p></div><div class="sect3" title="Bibliometrics, Shepardizing, and Social Network Analysis"><div class="titlepage"><div><div><h4 class="title" id="section-5.5.3.3">Bibliometrics, Shepardizing, and Social Network Analysis</h4></div></div></div><p><span><a id="def_bibliometrics"/>Information scientists began studying the
                        structure of scientific citation, now called <em class="glossterm">bibliometrics</em>, nearly a century ago to identify influential
                        scientists and publications.</span> This analysis of the flow of ideas
                    through publications can identify <span class="quote">“<span class="quote">invisible colleges</span>”</span> of scientists who rely on each other’s research,
                    and recognize the emergence of new scientific disciplines or research areas.
                    Universities use bibliometrics to evaluate professors for promotion and tenure,
                    and libraries use it to select resources for their collections.<sup>[<a id="chapter-5-endnote-53" href="#ftn.chapter-5-endnote-53" class="footnote">312</a>]</sup></p><p><span><a id="def_Shepardizing"/>The expression of citation relationships between
                        documents is especially nuanced in legal contexts, where the use of legal
                        cases as precedents makes it essential to distinguish precisely where a new
                        ruling lies on the relational continuum between <span class="quote">“<span class="quote">Following</span>”</span> and
                            <span class="quote">“<span class="quote">Overruling</span>”</span> with respect to a case it cites. The analysis
                        of legal citations to determine whether a cited case is still good law is
                        called <span class="bold"><strong><a class="glossterm" href="go01.html#gloss_Shepardizing"><em class="glossterm">Shepardizing</em></a></strong></span> because
                        lists of cases annotated in this way were first published in the late 1800s
                        by <span class="personname"><span class="firstname">Frank</span> <span class="surname">Shepard</span></span>, a salesman for a legal publishing company.</span><sup>[<a id="chapter-5-endnote-54" href="#ftn.chapter-5-endnote-54" epub:type="noteref" class="footnote">313</a>]</sup></p><p><span class="orgname">Facebook</span>’s multi-billion dollar valuation after its 2012
                    initial public offering is based on its ability to exploit the structure of a
                    person’s social network to personalize advertisements for people and their
                        <span class="quote">“<span class="quote">friends</span>”</span> to whom they are connected. Many computer science
                    researchers are working to determine the important characteristics of people and
                    relationships that best identify the people whose activities or messages
                    influence others to spend money.<sup>[<a id="chapter-5-endnote-55" href="#ftn.chapter-5-endnote-55" epub:type="noteref" class="footnote">314</a>]</sup></p></div></div></div><div class="sect1" title="The Architectural Perspective"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="section-5.6">The Architectural Perspective</h2></div></div></div><p>The architectural perspective emphasizes the number and abstraction level of the
            components of a relationship, which together characterize the complexity of the
            relationship. We will briefly consider three architectural issues: degree (or arity),
            cardinality, and directionality.</p><div class="sect2" title="Degree"><div class="titlepage"><div><div><h3 class="title" id="section-5.6.1">Degree</h3></div></div></div><p><a id="id631631" class="indexterm"/><a id="id631644" class="indexterm"/><span><a id="def_degree"/>The <a class="glossterm" href="go01.html#gloss_degree"><em class="glossterm">degree</em></a> or <a class="glossterm" href="go01.html#gloss_arity"><em class="glossterm">arity</em></a> of a relationship is the number of
                    entity types or categories of resources in the relationship. This is usually,
                    though not always, the same as the number of arguments in the relationship
                    expression.</span></p><div class="informalexample"><div class="literallayout"><p>    <span class="strong"><strong>Homer Simpson (husband) <span class="symbol">⇔</span> is-married-to <span class="symbol">⇔</span> Marge Simpson (wife)</strong></span></p></div></div><p>is a relationship of degree 2, a <span class="strong"><strong>binary</strong></span>
                relationship between two entity types, because the <span class="quote">“<span class="quote">is-married-to</span>”</span>
                relationship as we first defined it requires one of the arguments to be of entity
                type <span class="quote">“<span class="quote">husband</span>”</span> and one of them to be of type
                <span class="quote">“<span class="quote">wife.</span>”</span></p><p>Now suppose we change the definition of marriage to allow the two participants in
                a marriage to be any instance of the entity type <span class="quote">“<span class="quote">person.</span>”</span> The
                relationship expression looks exactly the same, but its degree is now <em class="glossterm">unary</em> because only 1 entity type is needed to
                instantiate the two arguments:</p><div class="informalexample"><div class="literallayout"><p>    <span class="strong"><strong>Homer Simpson (person) <span class="symbol">⇔</span> is-married-to <span class="symbol">⇔</span> Marge Simpson (person)</strong></span></p></div></div><p>Some relationships are best expressed as <em class="glossterm">ternary</em> ones that involve three different entity types. An example
                that appears in numerous data modeling books is one like this:</p><div class="informalexample"><div class="literallayout"><p>    <span class="strong"><strong>Supplier <span class="symbol">→</span> provides <span class="symbol">→</span> Part <span class="symbol">→</span> assembled-in <span class="symbol">→</span> Product</strong></span></p></div></div><p>It is always possible to represent ternary relationships as a set of binary ones
                by creating a new entity type that relates to each of the others in turn. This new
                entity type is called a dummy in modeling practice.</p><div class="informalexample"><div class="literallayout"><p>    <span class="strong"><strong>Supplier <span class="symbol">→</span> provides <span class="symbol">→</span> DUMMY</strong></span><br/>
    <span class="strong"><strong>Part <span class="symbol">→</span> provided-for <span class="symbol">→</span> DUMMY</strong></span><br/>
    <span class="strong"><strong>DUMMY <span class="symbol">→</span> assembled-in <span class="symbol">→</span> Product</strong></span></p></div></div><p>This transformation from a sensible ternary relationship to three binary ones
                involving a DUMMY entity type undoubtedly seems strange, but it enables all
                relationships to be binary while still preserving the meaning of the original
                ternary one. Making all relationships binary makes it easier to store relationships
                and combine them to discover new ones.</p></div><div class="sect2" title="Cardinality"><div class="titlepage"><div><div><h3 class="title" id="section-5.6.2">Cardinality</h3></div></div></div><p><span><a id="def_cardinality"/>The <a class="glossterm" href="go01.html#gloss_cardinality"><em class="glossterm">cardinality</em></a> of a relationship is the
                    number of instances that can be associated with each entity type in a
                    relationship.</span> At first glance this might seem to be degree by another
                name, but it is not.</p><p>Cardinality is easiest to explain for binary relationships. If we return to Homer
                and Marge, the binary relationship that expresses that they are married husband and
                wife is a <span class="strong"><strong>one-to-one</strong></span> relationship because a
                husband can only have one wife and a wife can only have one husband (at a time, in
                monogamous societies like the one in which the Simpsons live).</p><p>In contrast, the <span class="quote">“<span class="quote">is-parent-of</span>”</span> relationship is one-to-many, because
                the meaning of being a parent makes it correct to say that:</p><div class="informalexample"><div class="literallayout"><p><span class="strong"><strong>Homer Simpson <span class="symbol">→</span> is-parent-of <span class="symbol">→</span> Bart AND Lisa AND Maggie</strong></span></p></div></div><p>As we did with the ternary relationship in <a class="xref" href="ch05.html#section-5.6.1" title="Degree">Degree</a>, we can
                transform this more complex relationship architecture to a set of simpler ones by
                restricting expressions about being a parent to the one-to-one cardinality.</p><div class="informalexample"><div class="literallayout"><p>    <span class="strong"><strong>Homer Simpson <span class="symbol">→</span> is-parent-of <span class="symbol">→</span> Bart</strong></span><br/>
    <span class="strong"><strong>Homer Simpson <span class="symbol">→</span> is-parent-of <span class="symbol">→</span> Lisa</strong></span><br/>
    <span class="strong"><strong>Homer Simpson <span class="symbol">→</span> is-parent-of <span class="symbol">→</span> Maggie</strong></span></p></div></div><p>The one-to-many expression brings all three of Homer’s children together as
                arguments in the same relational expression, making it more obvious that they share
                the same relationship than in the set of separate and redundant one-to-one
                expressions.</p></div><div class="sect2" title="Directionality"><div class="titlepage"><div><div><h3 class="title" id="section-5.6.3">Directionality</h3></div></div></div><p><a id="id632090" class="indexterm"/><a id="id632101" class="indexterm"/><a id="id632114" class="indexterm"/><span><a id="def_directionality"/>The <a class="glossterm" href="go01.html#gloss_directionality"><em class="glossterm">directionality</em></a> of a relationship defines the order in which the
                    arguments of the relationship are connected. A <a class="glossterm" href="go01.html#gloss_one-way"><em class="glossterm">one-way</em></a> or <a class="glossterm" href="go01.html#gloss_one-way"><em class="glossterm">uni-directional</em></a> relationship can be
                    followed in only one direction, whereas a <em class="glossterm">bi-directional</em> one can be followed in both
                directions.</span></p><p>All symmetric relationships (<a class="xref" href="ch05.html#section-5.3.2.1" title="Symmetry">Symmetry</a>) are
                bi-directional, but not all bi-directional relationships are symmetric. A
                relationship between a manager and an employee that he manages is
                    <span class="quote">“<span class="quote">employs,</span>”</span> a different meaning than the
                    <span class="quote">“<span class="quote">is-employed-by</span>”</span> relationship in the opposite direction. As in this
                example, the relationship is often lexicalized in only one direction.</p></div></div><div class="sect1" title="The Implementation Perspective"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="section-5.7">The Implementation Perspective </h2></div></div></div><p>Finally, the <span><a class="glossterm" href="go01.html#gloss_implementation_perspective"><em class="glossterm">implementation perspective</em></a> on
                relationships considers how a relationship is realized or encoded in a technology
                context. The implementation perspective contrasts strongly with the conceptual,
                structural, and architectural perspectives, which emphasize the meaning and abstract
                structure of relationships. The implementation perspective is a superset of the
                lexical perspective, because the choice of the language in which to express a
                relationship is an implementation decision. However, most people think of
                implementation as all of the decisions about technological form rather
                than just about the choice of words.</span></p><p>In this book we focus on the fundamental issues and challenges that apply to all
            organizing systems, and not just on information-intensive ones that rely extensively on
            technology. Even with this reduced scope, there are some critical implementation
            concerns about the notation, syntax, and deployment of the relationships and other
            descriptions about resources. We briefly introduce some of these issues here and then
            discuss them in detail in <a class="xref" href="ch08.html" title="Chapter 8. The Forms of Resource Descriptions">Chapter 8</a>.</p><div class="sect2" title="Choice of Implementation"><div class="titlepage"><div><div><h3 class="title" id="section-5.7.1">Choice of Implementation</h3></div></div></div><p>The choice of implementation determines how easy it is to understand and process a
                set of relationships. For example, the second sentence of this chapter is a natural
                language implementation of a set of relationships in the Simpson family:</p><div class="blockquote"><blockquote class="blockquote"><p><span class="strong"><strong>The Simpson family includes a man named Homer and a
                        woman named Marge, the married parents of three sibling children, a boy
                        named Bart and two girls, Lisa and Maggie.</strong></span></p></blockquote></div><p>A subject-predicate-object syntax makes the relationships more explicit:</p><div class="example"><a id="id632284"/><div class="example-title">Example 5-1. Subject-Predicate Syntax</div><div class="example-contents"><div class="literallayout"><p>    <span class="bold"><strong>Homer Simpson → is-married-to → Marge Simpson<br/>
    Homer Simpson → is-parent-of → Bart<br/>
    Homer Simpson → is-parent-of → Lisa<br/>
    Homer Simpson → is-parent-of → Maggie<br/>
    Marge Simpson → is-married-to → Homer Simpson<br/>
    Marge Simpson → is-parent-of → Bart<br/>
    Marge Simpson → is-parent-of → Lisa<br/>
    Marge Simpson → is-parent-of → Maggie<br/>
    Bart Simpson → is-a → Boy<br/>
    Lisa Simpson → is-a → Girl<br/>
    Maggie Simpson → is-a → Girl</strong></span></p></div></div></div><p>In the following example of a potential <abbr class="abbrev">XML</abbr> implementation
                syntax, we emphasize class inclusion relationships by using elements as containers,
                and the relationships among the members of the family are expressed explicitly
                through references, using <abbr class="abbrev">XML</abbr>’s ID and IDREF attribute types:<sup>[<a id="id632384" href="#ftn.id632384" epub:type="noteref" class="footnote">315</a>]</sup></p><div class="example"><a id="id632276"/><div class="example-title">Example 5-2. An XML Implementation Syntax</div><div class="example-contents"><div class="literallayout"><p>&lt;Family name="Simpson"&gt;<br/>
    &lt;Parents children="Bart Lisa Maggie"&gt;<br/>
        &lt;Father name="Homer” spouse="Marge”  /&gt;<br/>
        &lt;Mother name="Marge” spouse="Homer”  /&gt;<br/>
    &lt;/Parents&gt;<br/>
    &lt;Children parents="Homer Marge” &gt;<br/>
        &lt;Boy name="Bart” siblings="Lisa Maggie” /&gt;<br/>
        &lt;Girl name="Lisa” siblings="Bart Maggie” /&gt;<br/>
        &lt;Girl name="Maggie” siblings="Bart Lisa” /&gt;<br/>
    &lt;/Children&gt;<br/>
&lt;/Family&gt; </p></div></div></div><p>None of the models we have presented so far in this chapter represents the
                complexities of modern families that involve multiple marriages and children from
                more than one marriage, but they are sufficient for our limited demonstration
                purposes.</p></div><div class="sect2" title="Syntax and Grammar"><div class="titlepage"><div><div><h3 class="title" id="section-5.7.2">Syntax and Grammar</h3></div></div></div><p><span><a id="def_syntax_grammar"/>The <span class="bold"><strong><a class="glossterm" href="go01.html#gloss_syntax"><em class="glossterm">syntax</em></a></strong></span>
                    and <span class="bold"><strong><a class="glossterm" href="go01.html#gloss_grammar"><em class="glossterm">grammar</em></a></strong></span> of a language consists of the rules that
                    determine which combinations of its words are allowed and are thus grammatical
                    or <span class="bold"><strong><em class="glossterm">well-formed.</em></strong></span> Natural languages differ immensely in
                    how they arrange nouns, verbs, adjectives, and other parts of speech to create
                    sentences.</span>
                <a id="id632491" class="indexterm"/>
                <a id="id632497" class="indexterm"/>Conformance to these rules makes the sentence syntactically compliant
                but does not mean that an expression is semantically comprehensible; the classic
                example is Chomsky’s anomalous sentence:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: none"><p><span class="strong"><strong>Colorless green ideas sleep
                        furiously</strong></span></p></li></ul></div><p>Any meaning this sentence has is odd, difficult to visualize, and outside of
                readily accessible experience, but anyone who knows the English language can
                recognize that it follows its syntactic rules, as opposed to this sentence, which
                breaks them and seems completely meaningless:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: none"><p><span class="strong"><strong>Ideas colorless sleep furiously
                            green</strong></span><sup>[<a id="chapter-5-endnote-56" href="#ftn.chapter-5-endnote-56" class="footnote">316</a>]</sup></p></li></ul></div></div><div class="sect2" title="Requirements for Implementation Syntax"><div class="titlepage"><div><div><h3 class="title" id="section-5.7.3">Requirements for Implementation Syntax</h3></div></div></div><p>The most basic requirement for implementation syntax is that it can represent all
                the expressions that it needs to express. For the examples in this chapter we used
                an informal combination of English words and symbols (arrows and parentheses) that
                you could understand easily, but simple language is incapable of expressing most of
                what we readily say in English. But this benefit of natural language only accrues to
                people, and the more restrictive and formal syntax is easier to understand for
                computers.</p><p>A second consideration is that the implementation can be understood and used by
                its intended users. We can usually express a relationship in different languages
                while preserving its meaning, just as we can usually implement the same computing
                functionality in different programming languages. From a semantic perspective these
                three expressions are equivalent:</p><div class="informalexample"><div class="literallayout"><p>        <span class="strong"><strong>My name is Homer Simpson</strong></span><br/>
        <span xml:lang="fr" class="strong"><strong>Mon nom est Homer Simpson</strong></span><br/>
        <span xml:lang="de" class="strong"><strong>Mein name ist Homer Simpson</strong></span></p></div></div><p>However, whether these expressions are equivalent for someone reading them depends
                on which languages they understand.</p><p>An analogous situation occurs with the implementation of web pages.
                    <abbr class="abbrev">HTML</abbr> was invented as a language for encoding how web pages look
                in a browser, and most of the tags in <abbr class="abbrev">HTML</abbr> represent the simple
                structure of an analogous print document. Representing paragraphs, list items and
                numbered headings with <code class="sgmltag-starttag">&lt;P&gt;</code> and <code class="sgmltag-starttag">&lt;LI&gt;</code> and <code class="sgmltag-starttag">&lt;H<em class="replaceable"><code>n</code></em>&gt;</code> makes using <abbr class="abbrev">HTML</abbr>
                so easy that school children can create web pages. However, the <span class="quote">“<span class="quote">web for
                    eyes</span>”</span> implemented using <abbr class="abbrev">HTML</abbr> is of less efficient or
                practical for computers that want to treat content as product catalogs, orders,
                invoices, payments, and other business transactions and information that can be
                analyzed and processed. This <span class="quote">“<span class="quote">web for computers</span>”</span> is best implemented
                using domain-specific vocabularies in <abbr class="abbrev">XML</abbr>.</p></div></div><div class="sect1" title="Relationships in Organizing Systems"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="section-5.8">Relationships in Organizing Systems</h2></div></div></div><p>In the previous sections as we surveyed the five perspectives on analyzing
            relationships we mentioned numerous examples where relationships had important roles in
            organizing systems. In this final section we examine three contexts for organizing
            systems where relationships are especially fundamental; the <a class="glossterm" href="go01.html#gloss_semantic_web"><em class="glossterm">Semantic Web</em></a> and Linked Data, bibliographic
            organizing systems, and situations involving system integration and
            interoperability.</p><div class="sect2" title="The Semantic Web and Linked Data"><div class="titlepage"><div><div><h3 class="title" id="section-5.8.1">The Semantic Web and Linked Data</h3></div></div></div><p>In a classic 2001 paper, <span class="personname"><span class="firstname">Tim</span> <span class="surname">Berners-Lee</span></span> laid out a vision of a <a class="glossterm" href="go01.html#gloss_semantic_web"><em class="glossterm">Semantic Web</em></a> in which all information could be shared and processed
                by automated tools as well as by people.<sup>[<a id="chapter-5-endnote-57" href="#ftn.chapter-5-endnote-57" epub:type="noteref" class="footnote">317</a>]</sup>
                <a id="id632890" class="indexterm"/><a id="id632873" class="indexterm"/>The essential technologies for making the web more semantic and
                relationships among web resources more explicit are applications of
                    <abbr class="abbrev">XML</abbr>, including <abbr class="abbrev">RDF</abbr> (<a class="xref" href="ch04.html#section-4.2.2.3" title="Tagging of Web-Based Resources">Tagging of Web-Based Resources</a>), and <abbr class="abbrev">OWL</abbr> (<a class="xref" href="ch05.html#section-5.3.3" title="Ontologies">Ontologies</a>). Many tools have been developed to support more
                semantic encoding, but most still require substantial expertise in semantic
                technologies and web standards.<sup>[<a id="chapter-5-endnote-58" href="#ftn.chapter-5-endnote-58" class="footnote">318</a>]</sup> More likely to succeed are applications that aim lower, not trying to
                encode all the latent semantics in a document or web page. For example, some wiki
                and blogging tools contain templates for semantic annotation, and
                    <span class="application">Wikipedia</span> has thousands of templates and <span class="quote">“<span class="quote">info
                    boxes</span>”</span> to encourage the creation of information in content-encoded
                formats.</p><p>The <span class="quote">“<span class="quote">Linked Data</span>”</span> movement is an extension of the <a class="glossterm" href="go01.html#gloss_semantic_web"><em class="glossterm">Semantic Web</em></a> idea to reframe the basic
                principles of the web’s architecture in more semantic terms. Instead of the limited
                role of links as simple untyped relationships between <abbr class="abbrev">HTML</abbr>
                documents, links between resources described by <abbr class="abbrev">RDF</abbr> can serve as
                the bridges between islands of semantic data, creating a Linked Data network or
                    cloud.<sup>[<a id="chapter-5-endnote-59" href="#ftn.chapter-5-endnote-59" class="footnote">319</a>]</sup></p></div><div class="sect2" title="Bibliographic Organizing Systems"><div class="titlepage"><div><div><h3 class="title" id="section-5.8.2">Bibliographic Organizing Systems</h3></div></div></div><p><a id="id633050" class="indexterm"/>Much of our thinking about relationships in organizing systems for information
                comes from the domain of bibliographic cataloging of library resources and the
                related areas of classification systems and descriptive thesauri. Bibliographic
                relationships provide an important means to build structure into library
                    catalogs.<sup>[<a id="chapter-5-endnote-60" href="#ftn.chapter-5-endnote-60" epub:type="noteref" class="footnote">320</a>]</sup></p><p><a id="id633085" class="indexterm"/><a id="id633089" class="indexterm"/>Bibliographic relationships are common among library resources.
                Smiraglia and Leazer found that approximately 30% of the works in the <em class="firstterm"><a id="first_OCLC"/><span class="citerefentry"><span class="refentrytitle"><span class="orgname">Online Computer Library
                            Center</span></span>(OCLC)</span></em>
                <span class="application">WorldCat</span> union catalog have associated derivative works.
                Relationships among items within these bibliographic families differ, but the
                average family size for those works with derivative works was found to be 3.54
                items. Moreover, <span class="quote">“<span class="quote">canonical</span>”</span> works that have strong cultural meaning
                and influence, such as <span class="quote">“<span class="quote">the plays of <span class="personname"><span class="firstname">William</span> <span class="surname">Shakespeare</span></span></span>”</span> and <em class="citetitle">The Bible</em>, have very large and
                complex bibliographic families.<sup>[<a id="chapter-5-endnote-61" href="#ftn.chapter-5-endnote-61" epub:type="noteref" class="footnote">321</a>]</sup></p><div class="sect3" title="Tillett’s Taxonomy and FRBR"><div class="titlepage"><div><div><h4 class="title" id="section-5.8.2.1">Tillett’s Taxonomy and FRBR</h4></div></div></div><p><a id="id633231" class="indexterm"/><a id="id633236" class="indexterm"/><a id="id633243" class="indexterm"/><a id="id633251" class="indexterm"/><a id="id633256" class="indexterm"/><a id="id633261" class="indexterm"/><a id="id633266" class="indexterm"/><a id="id633271" class="indexterm"/><a id="id633276" class="indexterm"/><a id="id633281" class="indexterm"/><a id="id633286" class="indexterm"/><span class="personname"><span class="firstname">Barbara</span> <span class="surname">Tillett</span></span>, in a study of 19<sup>th</sup> and
                        20<sup>th</sup> century catalog rules, found that many
                    different catalog rules have existed over time to describe bibliographic
                    relationships. She developed a taxonomy of bibliographic relationships that
                    includes equivalence, derivative, descriptive, whole-part, accompanying,
                    sequential or chronological, and shared characteristic. These relationship types
                    span the relationship perspectives defined in this chapter; equivalence,
                    derivative, and description are semantic types; whole-part and accompanying are
                    part semantic and part structural types; sequential or chronological are part
                    lexical and part structural types; and shared characteristics are part semantic
                    and part lexical types.<sup>[<a id="chapter-5-endnote-62" href="#ftn.chapter-5-endnote-62" epub:type="noteref" class="footnote">322</a>]</sup></p><p><a id="id633324" class="indexterm"/><a id="id633330" class="indexterm"/><a id="id633338" class="indexterm"/><a id="id633343" class="indexterm"/><a id="id633348" class="indexterm"/><a id="id633353" class="indexterm"/><a id="id633358" class="indexterm"/><a id="id633362" class="indexterm"/><a id="id633367" class="indexterm"/>Smiraglia expanded on Tillett’s derivative relationship to create
                    seven subtypes: simultaneous derivations, successive derivations, translations,
                    amplifications, extractions, adaptations, and performances.<sup>[<a id="chapter-5-endnote-63" href="#ftn.chapter-5-endnote-63" epub:type="noteref" class="footnote">323</a>]</sup></p><p><span>In <a class="xref" href="ch03.html#section-3.3.2" title="Identity and Bibliographic Resources">Identity and Bibliographic Resources</a>, <span class="quote">“<span class="quote">Identity
                            and Bibliographic Resources,</span>”</span> we briefly mentioned the four-level
                        abstraction hierarchy for resources introduced in the <span class="citerefentry"><span class="refentrytitle">Functional Requirements for Bibliographic
                                Records</span></span> report. <abbr class="abbrev">FRBR</abbr> was highly influenced by
                        Tillett’s studies of bibliographic relationships, and prescribes how the
                        relationships among resources at different levels are to be expressed
                        (work-work, expression-expression, work-expression,
                        expression-manifestation, and so on).</span></p></div><div class="sect3" title="Resource Description and Access (RDA)"><div class="titlepage"><div><div><h4 class="title" id="section-5.8.2.2">Resource Description and Access (RDA)</h4></div></div></div><p><a id="id633444" class="indexterm"/>Many cataloging researchers have recognized that online catalogs do not do a
                    very good job of encoding bibliographic relationships among items, both due to
                    catalog display design and to the limitations of how information is organized
                    within catalog records.<sup>[<a id="chapter-5-endnote-64" href="#ftn.chapter-5-endnote-64" epub:type="noteref" class="footnote">324</a>]</sup><a id="id633486" class="indexterm"/> Author name authority databases, for example, provide information
                    for variant author names, which can be very important in finding all of the
                    works by a single author, but this information is not held within a catalog
                    record. Similarly, <abbr class="abbrev">MARC</abbr> records can be formatted and displayed
                    in web library catalogs, but the data within the records are not available for
                    re-use, re-purposing, or re-arranging by researchers, patrons, or
                    librarians.</p><p><a id="id633518" class="indexterm"/>The <span><a id="ref_RDA"/><span class="citerefentry"><span class="refentrytitle">Resource Description and Access</span>(RDA)</span></span> next-generation cataloging rules are attempting to
                    bring together disconnected resource descriptions to provide more complete and
                    interconnected data about works, authors, publications, publishers, and subjects.<a id="id633497" class="indexterm"/></p><p><abbr class="abbrev">RDA</abbr> utilizes <abbr class="abbrev">RDF</abbr> to declare and store
                    relationships among bibliographic materials.<sup>[<a id="chapter-5-endnote-65" href="#ftn.chapter-5-endnote-65" epub:type="noteref" class="footnote">325</a>]</sup></p></div><div class="sect3" title="RDA and the Semantic Web"><div class="titlepage"><div><div><h4 class="title" id="section-5.8.2.3">RDA and the Semantic Web</h4></div></div></div><p>The move in <abbr class="abbrev">RDA</abbr> to encode bibliographic data in
                        <abbr class="abbrev">RDF</abbr> stems from the desire to make library catalog data more
                    web-accessible. As web-based data mash-ups, application programming interfaces
                    (APIs), and web searching are becoming ubiquitous and expected, library data are
                    becoming increasingly isolated. The developers of <abbr class="abbrev">RDA</abbr> see
                        <abbr class="abbrev">RDF</abbr> as the means for making library data more widely
                    available online.<sup>[<a id="chapter-5-endnote-66" href="#ftn.chapter-5-endnote-66" epub:type="noteref" class="footnote">326</a>]</sup></p><p><a id="id633616" class="indexterm"/><a id="id633632" class="indexterm"/><a id="id633640" class="indexterm"/>In addition to simply making library data more web accessible,
                        <abbr class="abbrev">RDA</abbr> seeks to leverage the distributed nature of the
                    Semantic Web. Once rules for describing resources, and the relationships between
                    them, are declared in <abbr class="abbrev">RDF</abbr> syntax and made publicly available,
                    the rules themselves can be mixed and mashed up. Creators of information systems
                    that use <abbr class="abbrev">RDF</abbr> can choose elements from any <abbr class="abbrev">RDF</abbr>
                    schema. For example, we can use the Dublin Core metadata schema (which has been
                    aligned with the <abbr class="abbrev">RDF</abbr> model) and the <span class="citerefentry"><span class="refentrytitle">Friend of a Friend</span>(FOAF)</span> schema (a schema to describe people and the relationships
                    between them) to create a set of metadata elements about a journal article that
                    goes beyond the standard bibliographic information. <abbr class="abbrev">RDA</abbr>’s
                    process of moving to <abbr class="abbrev">RDF</abbr> is well underway.<sup>[<a id="chapter-5-endnote-67" href="#ftn.chapter-5-endnote-67" epub:type="noteref" class="footnote">327</a>]</sup></p></div></div><div class="sect2" title="Integration and Interoperability"><div class="titlepage"><div><div><h3 class="title" id="section-5.8.3">Integration and Interoperability</h3></div></div></div><p><a id="id633822" class="indexterm"/><a id="id633832" class="indexterm"/><span><a id="def_integration2"/><a class="glossterm" href="go01.html#gloss_integration"><em class="glossterm">Integration</em></a> is the controlled sharing of information between
                    two (or more) business systems, applications, or services within or between
                    firms. Integration means that one party can extract or obtain information from
                    another one, it does not imply that the recipient can make use of the
                    information.</span></p><p><a id="id633859" class="indexterm"/><a id="id633870" class="indexterm"/><span><a id="def_interoperability"/><a class="glossterm" href="go01.html#gloss_interoperability"><em class="glossterm">Interoperability</em></a> goes beyond
                    integration to mean that systems, applications, or services that exchange
                    information can make sense of what they receive. Interoperability can involve
                    identifying corresponding components and relationships in each system,
                    transforming them syntactically to the same format, structurally to the same
                    granularity, and semantically to the same meaning.</span></p><p>For example, an Internet shopping site might present customers with a product
                catalog whose items come from a variety of manufacturers who describe the same
                products in different ways. Likewise, the end-to-end process from customer ordering
                to delivery requires that customer, product and payment information pass through the
                information systems of different firms. Creating the necessary information mappings
                and transformations is tedious or even impossible if the components and
                relationships among them aren’t formally specified for each system.</p><p>In contrast, when these models exist as data or document schemas or as classes in
                programming languages, identifying and exploiting the relationships between the
                information in different systems to achieve interoperability or to merge different
                classification systems can often be completely automated. Because of the substantial
                economic benefits to governments, businesses, and their customers of more efficient
                information integration and exchange, efforts to standardize these information
                models are important in numerous industries. <a class="xref" href="ch09.html" title="Chapter 9. Interactions with Resources">Chapter 9</a> will dive
                deeper into interoperability issues, especially those that arise in business
                contexts.</p></div></div><div class="sect1" title="Key Points in Chapter Five"><div class="titlepage"><div><div><h2 class="title" style="clear: both" id="section-5.9">Key Points in Chapter Five</h2></div></div></div><div class="highlights"><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>A relationship is <span class="quote">“<span class="quote">an association among several things, with that
                            association having a particular significance.</span>”</span></p></li><li class="listitem"><p>Just identifying the resources involved is not enough because several
                        different relationships can exist among the same resources.</p></li><li class="listitem"><p>Most relationships between resources can be expressed using a
                        subject-predicate-object model.</p></li><li class="listitem"><p>For a computer to understand relational expressions, it needs a
                        computer-processable representation of the relationships among words and
                        meanings that makes every important semantic assumption and property precise
                        and explicit.</p></li><li class="listitem"><p>Three broad categories of semantic relationships are inclusion,
                        attribution, and possession.</p></li><li class="listitem"><p>A set of interconnected class inclusion relationships creates a hierarchy
                        called a taxonomy.</p></li><li class="listitem"><p>Classification is a class inclusion relationship between an instance and a
                        class.</p></li><li class="listitem"><p>Ordering and inclusion relationships are inherently transitive, enabling
                        inferences about class membership and properties.</p></li><li class="listitem"><p>Class inclusion relationships form a framework to which other kinds of
                        relationships attach, creating a network of relationships called an
                        ontology.</p></li><li class="listitem"><p>When words encode the semantic distinctions expressed by class inclusion,
                        the more specific class is called the hyponym; the more general class is the
                        hypernym.</p></li><li class="listitem"><p>A thesaurus uses lexical relationships to suggest which terms to
                        use.</p></li><li class="listitem"><p>Morphological analysis of how words in a language are created from smaller
                        units is heavily used in text processing.</p></li><li class="listitem"><p>Many types of resources have internal structure in additional to their
                        structural relationships with other resources.</p></li><li class="listitem"><p>The XPath language defines the structures and patterns in
                            <abbr class="abbrev">XML</abbr> documents used by <abbr class="abbrev">XML</abbr> forms,
                        queries, and transformations.</p></li><li class="listitem"><p>Many hypertext links are purely structural because there is no explicit
                        representation of the reason for the relationship.</p></li><li class="listitem"><p>Using the pattern of links between documents to understand the structure
                        of knowledge and the structure of the intellectual community that creates it
                        is an idea that is nearly a century old.</p></li><li class="listitem"><p>The essential technologies for making the web more semantic and
                        relationships among web resources more explicit are <abbr class="abbrev">XML</abbr>,
                            <abbr class="abbrev">RDF</abbr>, and <abbr class="acronym">OWL</abbr></p></li><li class="listitem"><p>Much of our thinking about relationships in organizing systems for
                        information comes from the domain of bibliographic cataloging of library
                        resources and the related areas of classification systems and descriptive
                        thesauri.</p></li><li class="listitem"><p>The <span class="citerefentry"><span class="refentrytitle">Resource Description and Access</span>(RDA)</span> next-generation cataloging rules are attempting to bring
                        together disconnected resource descriptions.</p></li><li class="listitem"><p>Integration is the controlled sharing of information between two (or more)
                        business systems, applications, or services within or between firms.</p></li><li class="listitem"><p>Interoperability goes beyond integration to mean that systems,
                        applications, or services that exchange information can make sense of what
                        they receive.</p></li></ul></div></div></div><div class="footnotes" epub:type="footnotes"><br/><hr style="width: 100; align: left;"/><div class="footnote" id="ftn.chapter-5-endnote-01"><p><sup>[<a href="#chapter-5-endnote-01" class="para">253</a>] </sup>[Citation] <a id="id622167" class="indexterm"/><em class="citetitle">The Simpsons</em> TV show began in 1989 and is now
                    the longest running scripted TV show ever. The official website is
                        <a class="ulink" href="http://www.thesimpsons.com" target="_top"><code class="uri">http://www.thesimpsons.com</code></a>. The show is dubbed into French,
                    Italian and Spanish for viewers in Quebec, France, Italy, Latin America and
                    Spain. <em class="citetitle">The Simpson’s Movie</em> has been dubbed into Mandarin
                    Chinese and Cantonese. (Yes, we know that Bart actually calls his father by his
                    first name, but that would mess up our example here.) For more information about Mandarin kinship terms
                    see
                    <a class="ulink" href="http://mandarin.about.com/od/vocabularylists/tp/family.htm" target="_top"><code class="uri">http://mandarin.about.com/od/vocabularylists/tp/family.htm</code></a>.</p></div><div class="footnote" id="ftn.chapter-5-endnote-02"><p><sup>[<a href="#chapter-5-endnote-02" class="para">254</a>] </sup>[Citation] <a id="id622258" class="indexterm"/>Kinship can be studied from both anthropological and biological
                    perspectives, which differ to the degree to which they emphasize social
                    relationships and genetic ones. Kinship has been systematically studied since
                    the nineteenth century: <a class="link" href="bi01.html#Morgan1871" title="Systems of Consanguinity and Affinity of the Human Family"><a id="cite_Morgan1871"/>(Morgan
                        1871/1997)</a> developed a system of kinship classification still taught
                    today. A detailed interactive web tutorial developed by <span class="personname"><span class="firstname">Brian</span> <span class="surname">Schwimer</span></span> can be found at
                        <a class="ulink" href="http://umanitoba.ca/faculties/arts/anthropology/kintitle.html" target="_top"><code class="uri">http://umanitoba.ca/faculties/arts/anthropology/kintitle.html</code></a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-03"><p><sup>[<a href="#chapter-5-endnote-03" class="para">255</a>] </sup>[Citation] <a id="id622360" class="indexterm"/>Kent’s <a id="id622370" class="indexterm"/><a class="link" href="bi01.html#Kent2012" title="Data and Reality: A Timeless Perspective on Perceiving and Managing Information in Our Imprecise World"><em class="citetitle">Data and Reality</em></a> was first published in 1978
                    with a second edition in 1998. Kent was a well-known and well-liked researcher
                    in data modeling at <abbr class="abbrev">IBM</abbr>, and his book became a cult classic. In
                    2012, seven years after Kent’s death, a third edition <a class="link" href="bi01.html#Kent2012" title="Data and Reality: A Timeless Perspective on Perceiving and Managing Information in Our Imprecise World"><a id="cite_Kent2012-5.1"/>(Kent and Hoberman 2012)</a>
                    came out, slightly revised and annotated but containing essentially the same
                    content as the book from 34 years earlier because its key issues about data
                    modeling are timeless.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-04"><p><sup>[<a href="#chapter-5-endnote-04" class="para">256</a>] </sup>[CogSci] <a id="id622891" class="indexterm"/><a id="id622914" class="indexterm"/><span class="quote">“<span class="quote">Semantic</span>”</span> is usually defined as <span class="quote">“<span class="quote">relating to
                        meaning or language</span>”</span> and that doesn’t seem helpful here. 
                    <span class="quote">“<span class="quote">Homer is married to Marge</span>”</span> is a semantic assertion, but <span class="quote">“<span class="quote">Homer is
                    standing next to Marge</span>”</span> is not.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-05"><p><sup>[<a href="#chapter-5-endnote-05" class="para">257</a>] </sup>[CogSci] <a id="id622991" class="indexterm"/><a id="id623004" class="indexterm"/><a id="id623012" class="indexterm"/>For decades important and vexing questions have been raised about
                    the specificity of these predicate-argument associations and how or when the
                    semantic constraints they embody combine with syntactic and contextual
                    constraints during the process of comprehending language. Consider how
                        <span class="quote">“<span class="quote">While in the operating room, the surgeon used a knife to cut the
                        ____</span>”</span> generates a different expectancy from the same predicate and
                    agent in <span class="quote">“<span class="quote">While at the fancy restaurant, the surgeon used a knife to cut
                        the ____.</span>”</span> See <a class="link" href="bi01.html#Elman2009" title="“On the meaning of words and dinosaur bones: Lexical knowledge without a lexicon”"><a id="cite_Elman2009"/>(Elman
                        2009)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-06"><p><sup>[<a href="#chapter-5-endnote-06" class="para">258</a>] </sup>[Law] <a id="id623215" class="indexterm"/><a id="id623246" class="indexterm"/>This book is not the place for the debate over the definition of
                    marriage. We aren’t bigots; we just don’t need this discussion here. If these
                    definitions upset you here, you will feel better in <a class="xref" href="ch05.html#section-5.6.1" title="Degree">Degree</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-07"><p><sup>[<a href="#chapter-5-endnote-07" class="para">259</a>] </sup>[CogSci] <a id="id623336" class="indexterm"/><a id="id623341" class="indexterm"/>Typically, when people use language they operate on the assumption
                    that everyone shares their model of the world, providing the common ground that
                    enables them to communicate. As we saw in <a class="xref" href="ch03.html" title="Chapter 3. Resources in Organizing Systems">Chapter 3</a> and <a class="xref" href="ch04.html" title="Chapter 4. Resource Description and Metadata">Chapter 4</a>, (because of the <a class="glossterm" href="go01.html#gloss_vocabulary_problem"><em class="glossterm">vocabulary problem</em></a> and
                    different purposes for using resources and language) this assumption is often
                    wrong, This paves the way for serious misunderstandings, since what is assumed
                    to be shared knowledge may not really be shared or understood the same
                    way.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-08"><p><sup>[<a href="#chapter-5-endnote-08" class="para">260</a>] </sup>[Citation] See <a class="link" href="bi01.html#Chaffin1984" title="“The similarity and diversity of semantic relations”"><a id="cite_Chaffin1984"/>(Chaffin and Herrmann
                                        1984)</a>, <a class="link" href="bi01.html#Storey1993" title="“Understanding Semantic Relationships”"><a id="cite_Storey1993-5.1"/>(Storey 1993)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-09"><p><sup>[<a href="#chapter-5-endnote-09" class="para">261</a>] </sup>[CogSci] <a id="id624188" class="indexterm"/><a id="id624208" class="indexterm"/><a id="id624212" class="indexterm"/>Which of these classifications is most relevant depends on
                            the context. In addition, there might be other Homer Simpsons who are
                            not cartoon characters or who are not married, so we might have to disambiguate this homonymy to make sure we referring to the intended Homer Simpson.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-10"><p><sup>[<a href="#chapter-5-endnote-10" class="para">262</a>] </sup>[Citation] <a class="link" href="bi01.html#Winston1987" title="“A taxonomy of part-whole relations”"><a id="cite_Winston1987-5.1"/>(Winston, Chaffin, and Herman 1987)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-11"><p><sup>[<a href="#chapter-5-endnote-11" class="para">263</a>] </sup>[Citation] <a class="link" href="bi01.html#Storey1993" title="“Understanding Semantic Relationships”"><a id="cite_Storey1993-5.2"/>(Storey 1993)</a>.</p></div><div class="footnote" id="ftn.chapter-5-endnote-12"><p><sup>[<a href="#chapter-5-endnote-12" class="para">264</a>] </sup>[Citation] <a id="id625054" class="indexterm"/><a id="id625064" class="indexterm"/>Martin is the animated gecko who is the advertising
                            spokesman for <span class="orgname">Geico Insurance</span>
                                (<a class="ulink" href="http://www.geico.com/" target="_top"><code class="uri">http://www.geico.com/</code></a>). Martin’s wit and cockney accent
                            make him engaging and memorable, and a few years ago he was voted the
                            favorite advertising icon in the US.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-13"><p><sup>[<a href="#chapter-5-endnote-13" class="para">265</a>] </sup>[Citation] <a class="link" href="bi01.html#Gentner1983" title="“Structure-mapping: A theoretical framework for analogy”"><a id="cite_Gentner1983"/>(Gentner
                                1983)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-14"><p><sup>[<a href="#chapter-5-endnote-14" class="para">266</a>] </sup>[Citation] (Miller and Johnson-Laird 1976, p 565).</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-15"><p><sup>[<a href="#chapter-5-endnote-15" class="para">267</a>] </sup>[CogSci] <a id="id625764" class="indexterm"/><a id="id625784" class="indexterm"/>An example of transitivity in meronymic relationships is:
                            (1) the carburetor is part of the engine, (2) the engine is part of the
                            car, (3) therefore, the carburetor is part of the car. Some people have
                            argued that meronomy isn’t transitive, but a closer look at their
                            supposed counter-examples suggests that they have confused different
                            types of meronymic relationships. See Section 5 in <a class="link" href="bi01.html#Winston1987" title="“A taxonomy of part-whole relations”"><a id="cite_Winston1987-5.2"/>(Winston, Chaffin,
                                and Herman 1987)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-16"><p><sup>[<a href="#chapter-5-endnote-16" class="para">268</a>] </sup>[Computing] <a id="id626246" class="indexterm"/><a id="id626261" class="indexterm"/><a id="id626270" class="indexterm"/><a id="id626276" class="indexterm"/><span class="quote">“<span class="quote">Ontology</span>”</span> is a branch of philosophy concerned with
                        what exists in reality and the general features and relations of whatever
                        that might be <a class="link" href="bi01.html#Hofweber2009" title="“Logic and Ontology”"><a id="cite_Hofweber2009"/>(Hofweber
                            2009)</a>. Computer science has adopted <span class="quote">“<span class="quote">ontology</span>”</span> to
                        refer to any computer-processable resource that represents the relationships
                        among words and meanings in some knowledge domain. See <a class="link" href="bi01.html#Gruber1993" title="“A Translation Approach to Portable Ontology Specifications”"><a id="cite_Gruber1993"/>(Gruber 1993)</a>, <a class="link" href="bi01.html#Guarino1998" title="“Formal Ontology and Information Systems”"><a id="cite_Guarino1998"/>(Guarino 1998)</a>.</p></div><div class="footnote" id="ftn.chapter-5-endnote-17"><p><sup>[<a href="#chapter-5-endnote-17" class="para">269</a>] </sup>[Citation] <a id="id626430" class="indexterm"/><span><a id="ref_OWL"/><span class="citerefentry"><span class="refentrytitle">Web Ontology Language</span>(OWL)</span>
                            <a class="ulink" href="http://www.w3.org/2004/OWL/" target="_top"><code class="uri">http://www.w3.org/2004/OWL/</code></a></span>.</p></div><div class="footnote" id="ftn.chapter-5-endnote-18"><p><sup>[<a href="#chapter-5-endnote-18" class="para">270</a>] </sup>[Citation] <a class="ulink" href="http://www.cyc.com/" target="_top"><code class="uri">http://www.cyc.com/</code></a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-19"><p><sup>[<a href="#chapter-5-endnote-19" class="para">271</a>] </sup>[CogSci] <a id="id626569" class="indexterm"/><a id="id626575" class="indexterm"/>Languages and cultures differ in how they distinguish and describe
                    kinship, so Bart might find the system of family organization easier to master
                    in some countries and cultures and more difficult in others.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-20"><p><sup>[<a href="#chapter-5-endnote-20" class="para">272</a>] </sup>[CogSci] <a id="id626625" class="indexterm"/>It isn’t quite this simple, because it depends on how we define
                    <span class="quote">“<span class="quote">word</span>”</span> <span class="symbol">—</span>polar bear and sea horse aren’t lexicalized but they
                    are a single meaning-bearing unit because we don’t decompose and reassemble
                    meaning from the two separate words. These <span class="quote">“<span class="quote">lexical gaps</span>”</span> differ
                    from language to language, whereas <span class="quote">“<span class="quote">conceptual gaps</span>”</span> <span class="symbol">—</span>the things
                    we can’t think of or directly experience, like the pull of gravity<span class="symbol">—</span> may be
                    innate and universal. We revisit this issue as <span class="quote">“<span class="quote">linguistic
                        relativity</span>”</span> in <a class="xref" href="ch06.html" title="Chapter 6. Categorization: Describing Resource Classes and Types">Chapter 6</a>. (See
                        <a class="link" href="bi01.html#Bentivogli2000" title="“Looking for lexical gaps”"><a id="cite_Bentivogli2000"/>Bentivogli and
                        Pianta 2000)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-21"><p><sup>[<a href="#chapter-5-endnote-21" class="para">273</a>] </sup>[Citation] This example comes from (Fellbaum 2010, pages 236-237). German has
                    a word <span class="emphasis"><em>Kufenfahrzeug</em></span> for vehicle on runners.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-22"><p><sup>[<a href="#chapter-5-endnote-22" class="para">274</a>] </sup>[Citation] <a class="link" href="bi01.html#Miller1998" title="“Nouns in WordNet”"><a id="cite_Miller1998"/>(Miller
                                1998)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-23"><p><sup>[<a href="#chapter-5-endnote-23" class="para">275</a>] </sup>[Citation] <a id="id627134" class="indexterm"/><a class="link" href="bi01.html#Bolshakov2004" title="“Synonymous Paraphrasing Using WordNet and Internet”"><a id="cite_Bolshakov2004"/>(Bolshakov and Gelbukh 2004)</a>, p, 314. The quote continues
                                <span class="quote">“<span class="quote">The references to <span class="quote">‘<span class="quote">some class</span>’</span> and to
                                    <span class="quote">‘<span class="quote">insignificant change</span>’</span> make this definition rather
                                vague, but we are not aware of any significantly stricter
                                definition. Hence the creation of synonymy dictionaries, which are
                                known to be quite large, is rather a matter of art and
                                insight.</span>”</span></p></div><div class="footnote" id="ftn.chapter-5-endnote-24"><p><sup>[<a href="#chapter-5-endnote-24" class="para">276</a>] </sup>[Citation] George Miller made many important contributions to the
                            study of mind and language during his long scientific career. His most
                            famous article, 
                            <a class="link" href="bi01.html#Miller1956" title="“The Magical Number Seven, Plus or Minus Two: Some Limits on our Capacity for Processing Information”"><a id="cite_Miller1956"/>“<span class="citetitle">The Magical Number Seven, Plus or Minus
                            Two</span>” (Miller 1956)</a>,
                            was seminal in its proposals about information organization in human
                            memory, even though it is one of the most misquoted scientific papers of
                            all time. Relatively late in his career Miller began the WordNet project
                            to build a semantic dictionary, which is now an essential resource in
                            natural language processing applications. See
                                <a class="ulink" href="http://wordnet.princeton.edu/" target="_top"><code class="uri">http://wordnet.princeton.edu/</code></a>.</p></div><div class="footnote" id="ftn.chapter-5-endnote-25"><p><sup>[<a href="#chapter-5-endnote-25" class="para">277</a>] </sup>[Citation] This navigation is easiest to carry out using the
                            commercial product called <span class="quote">“<span class="quote">The Visual Thesaurus</span>”</span> at
                                <a class="ulink" href="http://www.visualthesaurus.com/" target="_top"><code class="uri">http://www.visualthesaurus.com/</code></a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-26"><p><sup>[<a href="#chapter-5-endnote-26" class="para">278</a>] </sup>[CogSci] <a id="id627370" class="indexterm"/>These contrasting meanings for <span class="quote">“<span class="quote">bank</span>”</span> are clear
                            cases of polysemy, but there are often much subtler differences in
                            meaning that arise from context. The verb <span class="quote">“<span class="quote">save</span>”</span> seems to
                            mean something different in <span class="quote">“<span class="quote">The shopper saved...</span>”</span> versus
                                <span class="quote">“<span class="quote">The lifeguard saved...</span>”</span> although they overlap in some
                            ways. <a class="link" href="bi01.html#Fillmore2000" title="“Describing polysemy: The case of ‘crawl’”"><a id="cite_Fillmore2000"/>(Fillmore and
                                Atkins 2000)</a> and others have proposed definitions of
                            polysemy, but there is no rigorous test for determining when word
                            meanings diverge sufficiently to be called different senses.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-27"><p><sup>[<a href="#chapter-5-endnote-27" class="para">279</a>] </sup>[Computing] <a id="id627484" class="indexterm"/><a id="id627499" class="indexterm"/>Many techniques for using <span class="application">WordNet</span>
                            to calculate measures of semantic similarity have been proposed. See
                                <a class="link" href="bi01.html#Budanitsky2006" title="“Evaluating WordNet-based Measures of Lexical Semantic Relatedness”"><a id="cite_Budanitsky2006"/>(Budanitsky
                                and Hirst 2006)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-28"><p><sup>[<a href="#chapter-5-endnote-28" class="para">280</a>] </sup>[Citation] See <a class="link" href="bi01.html#Gross1990" title="“Adjectives in WordNet”"><a id="cite_Gross1990"/>(Gross
                                and Miller, 1990)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-29"><p><sup>[<a href="#chapter-5-endnote-29" class="para">281</a>] </sup>[Cogsci] <a id="id627657" class="indexterm"/><a id="id627703" class="indexterm"/><a id="id627708" class="indexterm"/>This type of <span class="quote">“<span class="quote">lexical asymmetry</span>”</span> is called
                                <span class="quote">“<span class="quote">markedness.</span>”</span> The broader or dominant term is the
                            unmarked one and the narrower one is the marked one. See <a class="link" href="bi01.html#Battistella1996" title="The Logic of Markedness"><a id="cite_Battistella1996"/>(Battistella
                                1996)</a>.</p></div><div class="footnote" id="ftn.chapter-5-endnote-30"><p><sup>[<a href="#chapter-5-endnote-30" class="para">282</a>] </sup>[Citation] <a id="id627908" class="indexterm"/><a id="id627917" class="indexterm"/>
                        <a class="ulink" href="http://www.loc.gov/library/libarch-thesauri.html" target="_top"><code class="uri">http://www.loc.gov/library/libarch-thesauri.html</code></a>,
                            <a class="ulink" href="http://www.getty.edu/research/tools/vocabularies/aat/index.html" target="_top"><code class="uri">http://www.getty.edu/research/tools/vocabularies/aat/index.html</code></a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-31"><p><sup>[<a href="#chapter-5-endnote-31" class="para">283</a>] </sup>[CogSci] <a id="id628197" class="indexterm"/><a id="id628210" class="indexterm"/>Languages differ a great deal in morphological complexity and in
                        the nature of their morphological mechanisms. Mandarin Chinese has
                        relatively few morphemes and few grammatical inflections, which leads to a
                        huge number of homophones. English is pretty average on this scale. A
                        popular textbook on morphology is <a class="link" href="bi01.html#Haspelmath2010" title="Understanding Morphology"><a id="cite_Haspelmath2010"/>(Haspelmath and Sims 2010)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-32"><p><sup>[<a href="#chapter-5-endnote-32" class="para">284</a>] </sup>[LIS] These so-called endocentric compounds essentially mean what the
                            morphemes would have meant separately. But if a
                                <span class="symbol">‘</span><span class="quote">“<span class="quote">birdcage</span>”</span> is exactly a
                                <span class="quote">“<span class="quote">bird cage,</span>”</span> what is gained by creating a new word? <a id="id628386" class="indexterm"/><a id="id628389" class="indexterm"/><a id="id628413" class="indexterm"/><a id="id628418" class="indexterm"/><a id="id628423" class="indexterm"/>This question has long been debated in subject
                            classification, where it is framed as the contrast between
                                <span class="quote">“<span class="quote">pre-coordination</span>”</span> and
                                <span class="quote">“<span class="quote">post-coordination.</span>”</span> For example, is it better to
                            pre-classify some resources as about <span class="quote">“<span class="quote">Sports Gambling</span>”</span> or
                            should such resources be found by intersecting those classified as about
                                <span class="quote">“<span class="quote">Sports</span>”</span> and about <span class="quote">“<span class="quote">Gambling.</span>”</span> See
                            <a class="link" href="bi01.html#Svenonius2000" title="The Intellectual Foundation of Information Organization"><a id="Svenonius2000-5.1"/>(Svenonius 2000, pages 187-192)</a>.</p></div><div class="footnote" id="ftn.chapter-5-endnote-33"><p><sup>[<a href="#chapter-5-endnote-33" class="para">285</a>] </sup>[CogSci] <a id="id628615" class="indexterm"/>English nouns have plural (book/books) and possessive forms
                            (the professor’s book), adjectives have comparatives and superlatives
                            (big/bigger/biggest), and regular verbs have only four inflected forms
                            (see <a class="ulink" href="http://cla.calpoly.edu/~jrubba/morph/morph.over.html" target="_top"><code class="uri">http://cla.calpoly.edu/~jrubba/morph/morph.over.html</code></a>).
                            In contrast, in Classical Greek each noun can have 11 word forms, each
                            adjective 30, and every regular verb over 300 <a class="link" href="bi01.html#Anderson2001c" title="“Morpholology”"><a id="cite_Anderson2001c"/>(Anderson
                                2001)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-34"><p><sup>[<a href="#chapter-5-endnote-34" class="para">286</a>] </sup>[Computing] <a id="id628696" class="indexterm"/><a id="id628704" class="indexterm"/>Of the five perspectives on relationships in this chapter, the
                    structural one comes closest to the meaning of <span class="quote">“<span class="quote">relation</span>”</span> in
                    mathematics and computer science, where a relation is a set of ordered elements
                        (<span class="quote">“<span class="quote">tuples</span>”</span>) of equal degree (<a class="xref" href="ch05.html#section-5.6.1" title="Degree">Degree</a>). A
                    binary relation is a set of element pairs, a ternary relation is a set of
                    3-tuples, and so on. The elements in each tuple are <span class="quote">“<span class="quote">related</span>”</span> but
                    they do not need to have any <span class="quote">“<span class="quote">significant association</span>”</span> or
                        <span class="quote">“<span class="quote">relationship</span>”</span> among them.</p></div><div class="footnote" id="ftn.chapter-5-endnote-35"><p><sup>[<a href="#chapter-5-endnote-35" class="para">287</a>] </sup>[Citation] <a id="id628767" class="indexterm"/><a id="id628748" class="indexterm"/><a class="link" href="bi01.html#Travers1969" title="“An experimental study of the small world problem”"><a id="cite_Travers1969"/>(Travers and
                        Milgram 1969)</a> was the groundbreaking study that demonstrated what
                    they called the <span class="quote">“<span class="quote">small world problem</span>”</span> by which any two arbitrarily
                    selected people were separated by an average of fewer than six links. See <a class="link" href="bi01.html#Markoff2011" title="“Separating you and me? 4.74 degrees”"><a id="cite_Markoff2011"/>(Markoff and Sengupta
                        2011)</a> for a recent article that describes a similar study using
                        <span class="application">Facebook</span> data. See
                        <a class="ulink" href="http://oracleofbacon.org/" target="_top"><code class="uri">http://oracleofbacon.org/</code></a> for a web-based demonstration based on
                    actor <span class="personname"><span class="firstname">Kevin</span> <span class="surname">Bacon</span></span>’s remarkable variety of roles and hence fellow actors in his
                    movies.</p></div><div class="footnote" id="ftn.chapter-5-endnote-36"><p><sup>[<a href="#chapter-5-endnote-36" class="para">288</a>] </sup>[Citation] <a id="id629003" class="indexterm"/>This seems like an homage to <span class="personname"><span class="firstname">Jimi</span> <span class="surname">Hendrix</span></span> based on the title from a 1967 song, <em class="citetitle">Third Stone
                            from the Sun</em> <a class="ulink" href="http://en.wikipedia.org/wiki/Third_Stone_from_the_Sun" target="_top">
                           <code class="uri">http://en.wikipedia.org/wiki/Third_Stone_from_the_Sun</code></a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-8-endnote-13"><p><sup>[<a href="#chapter-8-endnote-13" class="para">289</a>] </sup>[Computing] <a id="id629235" class="indexterm"/>The subfield of natural language processing called
                                <span class="quote">“<span class="quote">named entity recognition</span>”</span> has as its goal the creation
                            of mixed content by identifying people, companies, organizations, dates,
                            trademarks, stock symbols, and so on in unstructured text.</p></div><div class="footnote" id="ftn.id629289"><p><sup>[<a href="#id629289" class="para">290</a>] </sup>[Citation]
                            <a class="ulink" href="http://www.tei-c.org/release/doc/tei-p5-doc/en/html/ND.html" target="_top"><code class="uri">http://www.tei-c.org/release/doc/tei-p5-doc/en/html/ND.html</code></a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-37"><p><sup>[<a href="#chapter-5-endnote-37" class="para">291</a>] </sup>[Citation] See <a class="link" href="bi01.html#Holman2001" title="Definitive XSLT and XPath"><a id="cite_Holman2001-5.1"/>(Holman
                            2001)</a> or <a class="link" href="bi01.html#Tidwell2008" title="XSLT: Mastering XML Transformations"><a id="cite_Tidwell2008"/>(Tidwell 2008)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-38"><p><sup>[<a href="#chapter-5-endnote-38" class="para">292</a>] </sup>[Citation] See <a class="link" href="bi01.html#vanderVlist2007" title="Schematron"><a id="cite_vanderVlist2007"/>(van der Vlist 2007)</a> and schematron.org for overviews. See <a class="link" href="bi01.html#Hamilton2012" title="“Schematron in the Context of the Clinical Document Architecture (CDA)”"><a id="cite_Hamilton2012"/>(Hamilton and Wood
                            2012)</a> for a detailed case study.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-36a"><p><sup>[<a href="#chapter-5-endnote-36a" class="para">293</a>] </sup>[Citation] <a class="link" href="bi01.html#Walsh2010" title="DocBook 5: The Definitive Guide"><a id="cite_Walsh2010-5.1"/>(Walsh
                                2010)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-39"><p><sup>[<a href="#chapter-5-endnote-39" class="para">294</a>] </sup>[Citation] <a id="id629578" class="indexterm"/><a id="id629709" class="indexterm"/>These layout and typographic conventions are well known to
                        graphic designers <a class="link" href="bi01.html#Williams2012" title="The Non-Designer’s Design Book"><a id="cite_Williams2012"/>(Williams 2008)</a> but are also fodder for
                        more academic treatment in studies of visual language or semiotics <a class="link" href="bi01.html#Crow2010" title="Visible Signs: An Introduction to Semiotics in the Visual Arts"><a id="cite_Crow2010"/>(Crow 2010)</a>.</p></div><div class="footnote" id="ftn.chapter-5-endnote-40"><p><sup>[<a href="#chapter-5-endnote-40" class="para">295</a>] </sup>[Computing] <a id="id629673" class="indexterm"/><a id="id629681" class="indexterm"/><a id="id629764" class="indexterm"/><a class="link" href="bi01.html#Page1999" title="“The PageRank Citation Ranking: Bringing Order to the Web”"><a id="cite_Page1999-5.1"/>(Page, Brin,
                            Motwani, and Winograd 1999)</a> describes Page Rank when its
                        inventors were computer science graduate students at Stanford. It isn’t a
                        coincidence that the technique shares a name with one of its inventors,
                        Google co-founder and CEO Larry Page. <a class="link" href="bi01.html#Langville2012" title="Google’s Page Rank and Beyond: The Science of Search Engine Rankings"><a id="cite_Langville2012"/>(Langville and Meyer 2012)</a> is an
                        excellent textbook. The ultimate authority about how page rank works is
                        Google; see <span class="personname"><span class="firstname">Matt</span> <span class="surname">Cutts</span></span> at
                            <a class="ulink" href="http://www.google.com/competition/howgooglesearchworks.html" target="_top"><code class="uri">http://www.google.com/competition/howgooglesearchworks.html</code></a>.</p></div><div class="footnote" id="ftn.chapter-5-endnote-41"><p><sup>[<a href="#chapter-5-endnote-41" class="para">296</a>] </sup>[Citation] <a id="id629903" class="indexterm"/><a id="id629910" class="indexterm"/><a id="id629915" class="indexterm"/><a class="link" href="bi01.html#Bush1945" title="“As We May Think”"><a id="cite_Bush1945-5.1"/>(Bush
                                1945)</a>. <span class="quote">“<span class="quote">Wholly new forms of encyclopedias will appear,
                                ready made with a mesh of associative trails running through
                                them...</span>”</span> See
                                <a class="ulink" href="http://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/" target="_top"><code class="uri">http://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/</code></a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-42"><p><sup>[<a href="#chapter-5-endnote-42" class="para">297</a>] </sup>[Citation] <a class="link" href="bi01.html#Nelson1981" title="Literary Machines: The Report On, and Of, Project Xanadu Concerning Word Processing, Electronic Publishing, Hypertext, Thinkertoys, Tomorrow’s Intellectual Revolution, and Certain Other Topics Including Knowledge, Education and Freedom"><a id="cite_Nelson1981"/>(Nelson
                            1981)</a>. Also see  
                            <a class="link" href="bi01.html#Nelson1974" title="Computer Lib"><a id="cite_Nelson1974"/>Computer Lib/Dream Machines (Nelson 1974)</a> 
                            for an early example of Nelson’s non-linear book style.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-42a"><p><sup>[<a href="#chapter-5-endnote-42a" class="para">298</a>] </sup>[Computing] <a id="id630055" class="indexterm"/><a id="id630066" class="indexterm"/><a id="id630084" class="indexterm"/><a id="id630098" class="indexterm"/><a id="id630104" class="indexterm"/><a id="id630115" class="indexterm"/><span><a id="def_transclusion"/><a id="id630128" class="indexterm"/>The inclusion, by hypertext reference, of a resource or
                                part of a resource into another resource is called <span class="bold"><strong><a class="glossterm" id="term_transclusion" href="go01.html#gloss_transclusion"><em class="glossterm">transclusion</em></a></strong></span>.
                                Transclusion is normally performed automatically, without user
                                intervention. The inclusion of images in web documents is an example
                                of transclusion. Transclusion is a frequently used technique in
                                business and legal document processing, where re-use of consistent
                                and up-to-date content is essential to achieve efficiency and
                                consistency.</span></p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-43"><p><sup>[<a href="#chapter-5-endnote-43" class="para">299</a>] </sup>[Citation] <a id="id630213" class="indexterm"/><a class="link" href="bi01.html#Engelbart1963" title="“A Conceptual Framework for the Augmentation of Man’s Intellect”"><a id="cite_Engelbart1963"/>(Engelbart 1963)</a>
                            <span class="personname"><span class="firstname">Douglas</span> <span class="surname">Engelbart</span></span> credits Bush’s <a class="link" href="bi01.html#Bush1945" title="“As We May Think”">“<span class="citetitle">As We May Think</span>”</a>
                            article as his direct inspiration. Engelbart was in the <span class="orgname">US
                                Navy</span>, living in a hut in the South Pacific during the last
                            stages of <abbr class="abbrev">WWII</abbr> when he read  <a class="link" href="bi01.html#Bush1945" title="“As We May Think”"><em class="citetitle">The Atlantic</em></a> 
                            monthly magazine in which Bush’s article was
                            published.</p></div><div class="footnote" id="ftn.chapter-5-endnote-44"><p><sup>[<a href="#chapter-5-endnote-44" class="para">300</a>] </sup>[Citation] <a id="id630269" class="indexterm"/>Doug Engelbart’s demonstration has been called the Mother of
                            All Demos and can be seen in its entirety at
                                <a class="ulink" href="http://sloan.stanford.edu/MouseSite/1968Demo.html" target="_top"><code class="uri">http://sloan.stanford.edu/MouseSite/1968Demo.html</code></a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-44a"><p><sup>[<a href="#chapter-5-endnote-44a" class="para">301</a>] </sup>[Citation] <a class="link" href="bi01.html#Gillies2000" title="How the Web Was Born: The story of the World Wide Web"><a id="cite_Gillies2000"/>(Gillies
                                and Cailliau 2000)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-45"><p><sup>[<a href="#chapter-5-endnote-45" class="para">302</a>] </sup>[Computing] <a id="id630386" class="indexterm"/><a id="id630396" class="indexterm"/>Most web links are very simple in structure. The anchor text
                            in the linking document is wrapped in <code class="sgmltag-starttag">&lt;A&gt;</code> and <code class="sgmltag-endtag">&lt;/A&gt;</code> tags, with an
                                <code class="sgmltag-attribute">HREF</code> (hypertext reference)
                            attribute that contains the <abbr class="abbrev">URI</abbr> of the link destination
                            if it is in another page, or a reference to an ID attribute if the link
                            is to a different part of the same page. <abbr class="abbrev">HTML</abbr> also has
                            a <code class="sgmltag-starttag">&lt;LINK&gt;</code> tag, which, along with
                                <code class="sgmltag-starttag">&lt;A&gt;</code> have <code class="sgmltag-attribute">REL</code> (relationship) and <code class="sgmltag-attribute">REV</code> (reverse relationship) attributes
                            that enable the encoding of typed relationships in links. In a book
                            context for example, link relationships and reverse relations include
                            obvious candidates such as next, previous, parent, child, table of
                            contents, bibliography, glossary and index.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-46"><p><sup>[<a href="#chapter-5-endnote-46" class="para">303</a>] </sup>[Computing] <a id="id630515" class="indexterm"/><a id="id630470" class="indexterm"/><span>Using hypertext links as interaction controls is the
                                modern dynamic manifestation of cross references between textual
                                commentary and illustrations in books, a mechanism that dates from the 1500s <a class="link" href="bi01.html#Kilgour1998" title="The Evolution of the Book"><a id="cite_Kilgour1998-5.1"/>(Kilgour 1998)</a>. </span>
                            <span>Hypertext links can be viewed as state transition
                                controls in distributed collections of web-based resources; this design
                                philosophy is known as <span class="citerefentry"><span class="refentrytitle">Representational State Transfer</span>(REST)</span>. See <a class="link" href="bi01.html#Wilde2011" title="REST: From Research to Practice"><a id="cite_Wilde2011"/>(Wilde and Pautasso 2011)</a>.</span></p></div><div class="footnote" id="ftn.id630550"><p><sup>[<a href="#id630550" class="para">304</a>] </sup>[Citation] <a id="id630554" class="indexterm"/><a id="id630561" class="indexterm"/><a id="id630565" class="indexterm"/><a id="id630572" class="indexterm"/>Mosaic was developed in <span class="personname"><span class="firstname">Joseph</span> <span class="surname">Hardin</span></span>’s lab at the <span class="citerefentry"><span class="refentrytitle">National Center for Supercomputing
                                    Applications</span>(NCSA)</span>, hosted by the <span class="orgname">University of Illinois, at
                                Urbana/Champaign</span> by <span class="personname"><span class="firstname">Marc</span> <span class="surname">Andreesen</span></span>, <span class="personname"><span class="firstname">Eric</span> <span class="surname">Bina</span></span> and a team of student programmers. Mosaic was initially
                            developed on the Unix X Window System, which made it immediately
                            available on a wide variety of Unix and Linux systems. See
                            <a class="ulink" href="http://www.ncsa.illinois.edu/Projects/mosaic.html" target="_top"><code class="uri">http://www.ncsa.illinois.edu/Projects/mosaic.html</code></a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.id630677"><p><sup>[<a href="#id630677" class="para">305</a>] </sup>[Citation] <a class="link" href="bi01.html#Schatz1994" title="“NCSA Mosaic and the World Wide Web: Global Hypermedia Protocols for the Internet”"><a id="cite_Schatz1994"/>(Schatz and
                                Hardin 1994)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-47"><p><sup>[<a href="#chapter-5-endnote-47" class="para">306</a>] </sup>[Citation] See <a class="link" href="bi01.html#Lorch1989" title="“Text-signaling devices and their effects on reading and memory processes”"><a id="cite_Lorch1989"/>(Lorch 1989)</a>, <a class="link" href="bi01.html#Mann1988" title="“Rhetorical Structure Theory: A Theory of Text Organization”"><a id="cite_Mann1988"/>(Mann and Thomson 1988)</a>. For example,
                                an author might use <span class="quote">“<span class="quote">See</span>”</span> as in <span class="quote">“<span class="quote">See (Glushko et al. 2013)</span>”</span> when referring to this
                                chapter if it is consistent with his point of view. On the other
                                hand, that same author could use <span class="quote">“<span class="quote">but</span>”</span> as a contrasting
                                citation signal, writing <span class="quote">“<span class="quote">But see (Glushko et al. 2013)</span>”</span> to express the relationship that the
                                chapter disagrees with him.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-48"><p><sup>[<a href="#chapter-5-endnote-48" class="para">307</a>] </sup>[Citation] Before the web, most hypertexts implementations were
                                in stand-alone applications like <abbr class="abbrev">CD-ROM</abbr>
                                encyclopedias or in personal information management systems that
                                used <span class="quote">“<span class="quote">cards</span>”</span> or <span class="quote">“<span class="quote">notes</span>”</span> as metaphors
                                for the information units that were linked together, 
                                typically using rich taxonomies of <a class="glossterm" href="go01.html#gloss_link_type"><em class="glossterm">link types</em></a>. See <a class="link" href="bi01.html#Conklin1987" title="“Hypertext : An Introduction and Survey”"><a id="cite_Conklin1987"/>(Conklin
                                    1987)</a>, <a class="link" href="bi01.html#Conklin1988" title="“glBIS : A Hypertext Tool for Exploratory Policy Discussion”"><a id="cite_Conklin1988"/>(Conklin and Begeman 1988)</a>, and <a class="link" href="bi01.html#DeRose1989" title="“Expanding the Notion of Links”"><a id="cite_DeRose1989"/>(DeRose
                                1989)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-49"><p><sup>[<a href="#chapter-5-endnote-49" class="para">308</a>] </sup>[Computing] <a id="id630990" class="indexterm"/>Many of the pre-web hypertext designs of the 1980s and
                                1990s allowed for n-ary links. The Dexter hypertext reference model
                                    <a class="link" href="bi01.html#Halasz1994" title="“The Dexter Hypertext Reference Model”"><a id="cite_Halasz1994"/>(Halasz and
                                    Schwartz 1994)</a> elegantly describes the typical
                                architectures. However, there is some ambiguity in use of the term
                                binary in hypertext link architectures. One-to-one vs. one-to-many
                                is a cardinality distinction, and some people reserve binary to
                                discussion about degree. See <a class="xref" href="ch05.html#section-5.6" title="The Architectural Perspective">The Architectural Perspective</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-50"><p><sup>[<a href="#chapter-5-endnote-50" class="para">309</a>] </sup>[Citations] See <a class="link" href="bi01.html#Weinreich2001" title="“The Look of the Link—Concepts for the User Interface of Extended Hyperlinks”"><a id="cite_Weinreich2001"/>(Weinreich, Obendorf, and Lamersdorf
                                    2001)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-51"><p><sup>[<a href="#chapter-5-endnote-51" class="para">310</a>] </sup>[Computing] See <a class="link" href="bi01.html#Brailsford1999" title="“Separable Hyperstructure and Delayed Link Binding”"><a id="cite_Brailsford1999"/>(Brailsford 1999)</a>, <a class="link" href="bi01.html#Wilde2002" title="XPath, XLink, XPointer, and XML: A Practical Guide to Web Hyperlinking and Transclusion"><a id="cite_Wilde2002"/>(Wilde and Lowe
                                    2002)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-52"><p><sup>[<a href="#chapter-5-endnote-52" class="para">311</a>] </sup>[Computing] <a id="id631227" class="indexterm"/><a id="id631233" class="indexterm"/><a id="id631239" class="indexterm"/>Reachability is determined by calculating the transitive
                            closure of the link matrix. A classic and well written explanation is
                                <a class="link" href="bi01.html#Agrawal1989" title="“Efficient Management of Transitive Relationships in Large Data and Knowledge Bases”">(Agrawal, Borgida, and Jagadish
                                1989)</a>.</p></div><div class="footnote" id="ftn.chapter-5-endnote-53"><p><sup>[<a href="#chapter-5-endnote-53" class="para">312</a>] </sup>[LIS] <a id="id631339" class="indexterm"/><a id="id631363" class="indexterm"/><a id="id631368" class="indexterm"/><span class="personname"><span class="firstname">Eugene</span> <span class="surname">Garfield</span></span> developed many of the techniques for studying scientific
                            citation and he has been called the <span class="quote">“<span class="quote">grandfather of Google</span>”</span>
                                (<a class="ulink" href="http://blog.lib.uiowa.edu/hardinmd/2010/07/12/eugene-garfield-librarian-grandfather-of-google/" target="_top"><code class="uri">http://blog.lib.uiowa.edu/hardinmd/2010/07/12/eugene-garfield-librarian-grandfather-of-google/</code></a>)
                            because of Google’s use of citation patterns to determine relevance. See
                                <a class="link" href="bi01.html#Garfield2000" title="The Web of Knowledge: A Festschrift in Honor of Eugene Garfield"><a id="cite_Garfield2000"/>(Garfield,
                                Cronin, and Atkins 2000)</a> for a set of papers that review
                            Garfield’s many contributions. See <a class="link" href="bi01.html#BarIlan2008" title="“Informetrics at the beginning of the 21st century—A review”"><a id="cite_BarIlan2008"/>(Bar-Ilan 2008)</a> and <a class="link" href="bi01.html#Neuhaus2008" title="“Data sources for performing citation analysis: An overview”"><a id="cite_Neuhaus2008"/>(Neuhaus and Daniel
                                2008)</a> for recent reviews of data sources and citation
                            metrics.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-54"><p><sup>[<a href="#chapter-5-endnote-54" class="para">313</a>] </sup>[Law] <a id="id631457" class="indexterm"/>Shepard first put adhesive stickers into case books, then
                            published lists of cases and their citations. Shepardizing is a big
                            business for <span class="orgname">Lexis/Nexis</span> and
                                <span class="orgname">Westlaw</span> (where the technique is called
                                <span class="quote">“<span class="quote">KeyCite</span>”</span>).</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-55"><p><sup>[<a href="#chapter-5-endnote-55" class="para">314</a>] </sup>[Computing] <a id="id631527" class="indexterm"/>See <a class="link" href="bi01.html#Watts2004" title="“The ‘New’ Science of Networks”"><a id="cite_Watts2004"/>(Watts
                                2004)</a> for a detailed review of the theoretical foundations.
                            See <a class="link" href="bi01.html#Wu2012" title="The Science of Social: Beyond Hype, Likes, and Followers"><a id="cite_Wu2012"/>(Wu 2012)</a> for
                            applications in web-based social networks.</p></div><div class="footnote" epub:type="footnote" id="ftn.id632384"><p><sup>[<a href="#id632384" class="para">315</a>] </sup>[Computing] We are assuming a schema that establishes that the <code class="sgmltag-attribute">name</code> attributes are of type ID and that the
                        other attributes are of type IDREFS. This schema allows for polygamy, the
                        possibility of multiple values for the <code class="sgmltag-attribute">spouse</code> attribute. Restrictions on the number of spouses can
                        be enforced with Schematron. (Also see the
                        Sidebar, <a class="xref" href="ch08.html#sidebar_XML_Transclusion_Features" title="Inclusions and References">Inclusions and References</a>).</p></div><div class="footnote" id="ftn.chapter-5-endnote-56"><p><sup>[<a href="#chapter-5-endnote-56" class="para">316</a>] </sup>[Cite] <a id="id632535" class="indexterm"/><a class="link" href="bi01.html#Chomsky1957" title="Syntactic Structures"><a id="cite_Chomsky1957"/>(Chomsky 1957)</a> used these now famous sentences to
                                motivate the distinction between syntax and semantics. He argued
                                that since the probability in both cases that the words had
                                previously occurred in this order was essentially zero, statistics
                                of word occurrence could not be part of language knowledge. There is
                                a fascinating analysis of these sentences in
                                    <span class="application">Wikipedia</span>.
                                    <a class="ulink" href="http://en.wikipedia.org/wiki/Colorless_green_ideas_sleep_furiouslyendnote" target="_top"><code class="uri">http://en.wikipedia.org/wiki/Colorless_green_ideas_sleep_furiouslyendnote</code></a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-57"><p><sup>[<a href="#chapter-5-endnote-57" class="para">317</a>] </sup>[Computing] <a class="link" href="bi01.html#Berners-Lee2001" title="“The Semantic Web”"><a id="cite_Berners-Lee2001-5.1"/>(Berners-Lee, Hendler, and Lassila, 2001)</a> is the classic paper,
                        and <a class="link" href="bi01.html#Shadbolt2006" title="“The Semantic Web Revisited”"><a id="cite_Shadbolt2006"/>(Shadbolt, Hall, and
                            Berners-Lee 2006)</a> is something of a revisionist history.</p><p><a id="id632823" class="indexterm"/><a id="id632847" class="indexterm"/>Somewhat ironically, the web was not semantic from
                        the beginning because Berners-Lee made a conscious decision to implement
                        web documents using <abbr class="abbrev">HTML</abbr>, a presentation-oriented markup
                        language, rather than require markup to be content-oriented. Designing
                            <abbr class="abbrev">HTML</abbr> to be conceptually simple and easy to implement
                        rather than general and powerful led to its rapid adoption after invention
                        of the <em class="firstterm"><a id="first_NCSA"/><abbr class="abbrev">NCSA</abbr></em> Mosaic
                        graphical browser. Web documents encoded using <abbr class="abbrev">HTML</abbr> are
                        capable of expressing sophisticated assertions and relationships using
                            <code class="sgmltag-attribute">REL</code> and <code class="sgmltag-attribute">REV</code> attributes, but content creators rarely do so
                        because browser makers have not provided useful interactions for well-known
                        link relation types.</p></div><div class="footnote" id="ftn.chapter-5-endnote-58"><p><sup>[<a href="#chapter-5-endnote-58" class="para">318</a>] </sup>[Computing] <a id="id632937" class="indexterm"/>For example, <span class="application">Protégé</span>
                            (<a class="ulink" href="http://protege.stanford.edu/" target="_top"><code class="uri">http://protege.stanford.edu/</code></a>) 
                        <span class="symbol">—</span>a free, open-source
                        platform with a suite of tools to construct domain models and
                        knowledge-based applications with ontologies.</p></div><div class="footnote" id="ftn.chapter-5-endnote-59"><p><sup>[<a href="#chapter-5-endnote-59" class="para">319</a>] </sup>[Citation] See <a class="ulink" href="http://linkeddata.org/" target="_top"><code class="uri">http://linkeddata.org/</code></a> and <a class="xref" href="ch08.html#section-8.3.3" title="Syntax">Syntax</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-60"><p><sup>[<a href="#chapter-5-endnote-60" class="para">320</a>] </sup>[LIS] <a id="id633065" class="indexterm"/>Barbara Tillett has written extensively about the theory of
                        bibliographic relationships; <a class="link" href="bi01.html#Tillett2001" title="“Bibliographic Relationships”"><a id="cite_Tillett2001"/>(Tillett 2001)</a> is an especially useful
                        resource because it is a chapter in a comprehensive discussion ambitiously
                        titled <a class="link" href="bi01.html#Bean2001" title="Relationships in the Organization of Knowledge"><a id="cite_Bean2001"/><em class="citetitle">Relationships in the Organization of Knowledge</em>
                        (Bean and Green 2001)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-61"><p><sup>[<a href="#chapter-5-endnote-61" class="para">321</a>] </sup>[Citation] <a class="link" href="bi01.html#Smiraglia1999" title="“Derivative Bibliographic Relationships: The Work Relationship in a Global Bibliographic Database”"><a id="cite_Smiraglia1999"/>(Smiraglia and Leazer 1999)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-62"><p><sup>[<a href="#chapter-5-endnote-62" class="para">322</a>] </sup>[Citation] (Tillett 1991, 1992).</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-63"><p><sup>[<a href="#chapter-5-endnote-63" class="para">323</a>] </sup>[Citation] <a class="link" href="bi01.html#Smiraglia1994" title="“Derivative Bibliographic Relationships: Linkages in the Bibliographic Universe”"><a id="cite_Smiraglia1994"/>(Smiraglia 1994)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-64"><p><sup>[<a href="#chapter-5-endnote-64" class="para">324</a>] </sup>[Citation] <a class="link" href="bi01.html#Tillett2005" title="“FRBR and Cataloging for the Future”"><a id="cite_Tillett2005-5.1"/>(Tillett 2005)</a>.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-65"><p><sup>[<a href="#chapter-5-endnote-65" class="para">325</a>] </sup>[LIS] See Section 8.1.3.1.</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-66"><p><sup>[<a href="#chapter-5-endnote-66" class="para">326</a>] </sup>[Citation] See (Coyle 2010a).</p></div><div class="footnote" epub:type="footnote" id="ftn.chapter-5-endnote-67"><p><sup>[<a href="#chapter-5-endnote-67" class="para">327</a>] </sup>[LIS] <a id="id633698" class="indexterm"/><a id="id633709" class="indexterm"/><a id="id633716" class="indexterm"/><a id="id633725" class="indexterm"/><a id="id633731" class="indexterm"/>The <abbr class="abbrev">FRBR</abbr> entities, <abbr class="abbrev">RDA</abbr>
                            data elements, and <abbr class="abbrev">RDA</abbr> value vocabularies have been
                            defined in alignment with <abbr class="abbrev">RDF</abbr> using the Simple
                            Knowledge Organization System (<abbr class="abbrev">SKOS</abbr>).
                                <abbr class="abbrev">SKOS</abbr> is an <span class="quote">“<span class="quote"><abbr class="abbrev">RDF</abbr>-compliant
                                language specifically designed for term lists and thesauri</span>”</span>
                            <a class="link" href="bi01.html#Coyle2010b" title="“RDA in RDF”"><a id="cite_Coyle2010b"/>(Coyle 2010b)</a>.
                            The <abbr class="abbrev">SKOS</abbr> website provides lists of registered
                                <abbr class="abbrev">RDF</abbr> metadata schemas and vocabularies. From these,
                            information system designers can create application profiles for their
                            resources, selecting elements from multiple schemas, including
                                <abbr class="abbrev">FRBR</abbr> and <abbr class="abbrev">RDA</abbr> vocabularies.</p></div></div></section></body></html>
